
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tvopt package &#8212; tvopt 0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="tvopt-package">
<h1>tvopt package<a class="headerlink" href="#tvopt-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-tvopt.costs">
<span id="tvopt-costs-module"></span><h2>tvopt.costs module<a class="headerlink" href="#module-tvopt.costs" title="Permalink to this headline">¶</a></h2>
<p>Cost template definition and examples.</p>
<dl class="py class">
<dt id="tvopt.costs.AbsoluteValue">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">AbsoluteValue</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">weight</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.AbsoluteValue" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Scalar absolute value function.</p>
<dl class="py method">
<dt id="tvopt.costs.AbsoluteValue.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.AbsoluteValue.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.AbsoluteValue.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.AbsoluteValue.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.AbsoluteValue.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.AbsoluteValue.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id1"><span class="problematic" id="id2">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Constant">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Constant</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dom</span></em>, <em class="sig-param"><span class="n">c</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Constant" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Constant cost.</p>
<p>This class defines a constant, whose value is stored in the attribute <cite>c</cite>.
The <cite>gradient</cite> and <cite>hessian</cite> methods return 0, while the proximal acts
as an identity.</p>
<dl class="py attribute">
<dt id="tvopt.costs.Constant.dom">
<code class="sig-name descname">dom</code><a class="headerlink" href="#tvopt.costs.Constant.dom" title="Permalink to this definition">¶</a></dt>
<dd><p>The given cost domain, for compatibility with other costs.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set">sets.Set</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.Constant.c">
<code class="sig-name descname">c</code><a class="headerlink" href="#tvopt.costs.Constant.c" title="Permalink to this definition">¶</a></dt>
<dd><p>The constant value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.Constant.smooth">
<code class="sig-name descname">smooth</code><a class="headerlink" href="#tvopt.costs.Constant.smooth" title="Permalink to this definition">¶</a></dt>
<dd><p>The smoothness degree, set to 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Constant.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Constant.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost.</p>
<p>Returns the costant value.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Constant.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Constant.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient.</p>
<p>Returns 0.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Constant.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Constant.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian.</p>
<p>Returns 0.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Constant.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Constant.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>Acts as the identity, returning <cite>x</cite>.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Cost">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Cost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dom</span></em>, <em class="sig-param"><span class="n">time</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">prox_solver</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Cost" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Template for a cost function.</p>
<p>This class defines the template for a cost function</p>
<div class="math notranslate nohighlight">
\[f : \mathbb{R}^{n_1 \times n_2 \times \ldots} \times \mathbb{R}_+
\to \mathbb{R} \cup \{ +\infty \}\]</div>
<p>which depends on the unknown
<span class="math notranslate nohighlight">\(\pmb{x} \in \mathbb{R}^{n_1 \times n_2 \times \ldots}\)</span> and,
optionally, on the time <span class="math notranslate nohighlight">\(t \in \mathbb{R}_+\)</span>.</p>
<p><cite>Cost</cite> objects support the following operations:</p>
<blockquote>
<div><ul class="simple">
<li><p>negation</p></li>
<li><p>sum (by another cost or with a scalar),</p></li>
<li><p>product (by another cost or with a scalar),</p></li>
<li><p>division and power with a scalar.</p></li>
</ul>
</div></blockquote>
<p>A <cite>Cost</cite> object should expose, compatibly with the smoothness degree, the
methods <cite>function</cite>, <cite>gradient</cite>, <cite>hessian</cite>, <cite>proximal</cite>. The convention for
these methods is that the first positional argument is <span class="math notranslate nohighlight">\(\pmb{x}\)</span>,
and only a second positional argument is allowed, for <span class="math notranslate nohighlight">\(t\)</span>. Any other
argument should be passed as a keyword argument.</p>
<p>If the cost is time-varying, then it should expose the methods
<cite>time_derivative</cite> and <cite>sample</cite>, as well; see methods’ documentation for
the default behavior.</p>
<dl class="py attribute">
<dt id="tvopt.costs.Cost.dom">
<code class="sig-name descname">dom</code><a class="headerlink" href="#tvopt.costs.Cost.dom" title="Permalink to this definition">¶</a></dt>
<dd><p>The x domain <span class="math notranslate nohighlight">\(\mathbb{R}^{n_1 \times n_2 \times \ldots}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set">sets.Set</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.Cost.time">
<code class="sig-name descname">time</code><a class="headerlink" href="#tvopt.costs.Cost.time" title="Permalink to this definition">¶</a></dt>
<dd><p>The time domain <span class="math notranslate nohighlight">\(\mathbb{R}_+\)</span>. If the cost is static this is None.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tvopt.sets.T" title="tvopt.sets.T">sets.T</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.Cost.is_dynamic">
<code class="sig-name descname">is_dynamic</code><a class="headerlink" href="#tvopt.costs.Cost.is_dynamic" title="Permalink to this definition">¶</a></dt>
<dd><p>Attribute to check if the cost is static or dynamic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.Cost.smooth">
<code class="sig-name descname">smooth</code><a class="headerlink" href="#tvopt.costs.Cost.smooth" title="Permalink to this definition">¶</a></dt>
<dd><p>This attribute stores the smoothness degree of the cost, for example
it is <span class="math notranslate nohighlight">\(0\)</span> if the cost is continuous, <span class="math notranslate nohighlight">\(1\)</span> if the cost
is differentiable, <em>etc</em>. By convention it is <span class="math notranslate nohighlight">\(-1\)</span> if the cost
is discontinuous.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.Cost.prox_solver">
<code class="sig-name descname">prox_solver</code><a class="headerlink" href="#tvopt.costs.Cost.prox_solver" title="Permalink to this definition">¶</a></dt>
<dd><p>This attribute specifies the method (gradient or Newton) that should be
used to compute the proximal</p>
<div class="math notranslate nohighlight">
\[\text{prox}_{\rho f(\cdot; t)}(\pmb{x}) = \text{argmin}_{\pmb{y}}
\left\{ f(\pmb{y};t) + \frac{1}{2 \rho} \| \pmb{y} - \pmb{x} \|^2 \right\}\]</div>
<p>of the cost, if a closed form is not available. See also the auxiliary
function <cite>compute_proximal</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str or None</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>Not all operations preserve convexity.</p>
<dl class="py method">
<dt id="tvopt.costs.Cost.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Cost.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Cost.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Cost.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Cost.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Cost.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Cost.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Cost.proximal" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="simple">
<dt>x<span class="classifier">array_like</span></dt><dd><p>The x where the proximal should be evaluated.</p>
</dd>
<dt><a href="#id3"><span class="problematic" id="id4">*</span></a>args</dt><dd><p>The time at which the proximal should be evaluated. Not
required if the cost is static.</p>
</dd>
<dt>penalty<span class="classifier">float, optional</span></dt><dd><p>The penalty parameter :math:<a href="#id5"><span class="problematic" id="id6">`</span></a></p>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>ho` for the proximal evaluation.</dt><dd><blockquote>
<div><p>Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p>
</div></blockquote>
<dl class="simple">
<dt><a href="#id7"><span class="problematic" id="id8">**</span></a>kwargs</dt><dd><p>Any other required argument.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Cost.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Cost.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample the cost.</p>
<p>This method returns a <cite>SampledCost</cite> object which exposes the same
methods of the cost but fixing the time argument to <cite>t</cite>.</p>
<p>If the cost is static, the cost itself is returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> (<em>float</em>) – The time at which the cost should be sampled.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The sampled cost or, if static, the cost itself.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost">Cost</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Cost.time_derivative">
<code class="sig-name descname">time_derivative</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="n">der</span><span class="o">=</span><span class="default_value">'tx'</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Cost.time_derivative" title="Permalink to this definition">¶</a></dt>
<dd><p>A derivative w.r.t. time of the cost.</p>
<p>This method computes derivatives w.r.t. time of the cost, or mixed
derivatives w.r.t. both time and x (<em>e.g.</em> the derivative in time of
the gradient).</p>
<p>If this method is not overwritten, it computes the derivative by
default using <em>backward finite differences</em>. See
<cite>backward_finite_difference</cite> for details.</p>
<p>If the cost is static, <span class="math notranslate nohighlight">\(0\)</span> is returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the derivative should be evaluated.</p></li>
<li><p><strong>t</strong> (<em>float</em>) – The time at which the derivative should be evaluated.</p></li>
<li><p><strong>der</strong> (<em>str</em><em>, </em><em>optional</em>) – A sequence of “x” and “t” that chooses which derivative should be
computed. For example, the default “tx” denotes the derivative
w.r.t. time of the cost’s (sub-)gradient.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the number of “x” characters in <cite>der</cite> exceeds <span class="math notranslate nohighlight">\(2\)</span>.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The required derivative or <span class="math notranslate nohighlight">\(0\)</span>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array_like</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.DiscreteDynamicCost">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">DiscreteDynamicCost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">costs</span></em>, <em class="sig-param"><span class="n">t_s</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DiscreteDynamicCost" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Dynamic cost from a sequence of static costs.</p>
<p>This class creates a dynamic cost from a list of static costs. That is,
given a sampling time <span class="math notranslate nohighlight">\(T_\mathrm{s}\)</span>, the cost at time
<span class="math notranslate nohighlight">\(t_k = k T_\mathrm{s}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[f(\pmb{x}; t_k) = f_k(\pmb{x})\]</div>
<p>with <span class="math notranslate nohighlight">\(f_k\)</span> the k-th static cost in the list.</p>
<dl class="py method">
<dt id="tvopt.costs.DiscreteDynamicCost.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DiscreteDynamicCost.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DiscreteDynamicCost.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DiscreteDynamicCost.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DiscreteDynamicCost.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DiscreteDynamicCost.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DiscreteDynamicCost.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DiscreteDynamicCost.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id9"><span class="problematic" id="id10">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DiscreteDynamicCost.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DiscreteDynamicCost.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample the cost.</p>
<p>The difference with the default <cite>Cost</cite> method is that it returns a
cost in the list rather than a <cite>SampledCost</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> (<em>float</em>) – The time at which the cost should be sampled.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The closest cost in the list.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost">Cost</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.DynamicExample_1D">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">DynamicExample_1D</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t_s</span></em>, <em class="sig-param"><span class="n">t_max</span></em>, <em class="sig-param"><span class="n">omega</span><span class="o">=</span><span class="default_value">0.06283185307179587</span></em>, <em class="sig-param"><span class="n">kappa</span><span class="o">=</span><span class="default_value">7.5</span></em>, <em class="sig-param"><span class="n">mu</span><span class="o">=</span><span class="default_value">1.75</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_1D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Scalar benchmark dynamic cost.</p>
<p>The dynamic cost was propposed in [1]__ and is defined as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(x; t) = \frac{1}{2} (x - \cos(\omega t))^2 + \kappa \log(1 + \exp(\mu x))\]</div>
</div></blockquote>
<p>with default parameters <span class="math notranslate nohighlight">\(\omega = 0.02 \pi\)</span>, <span class="math notranslate nohighlight">\(\kappa = 7.5\)</span>
and <span class="math notranslate nohighlight">\(\mu = 1.75\)</span>.</p>
<dl class="footnote brackets">
<dt class="label" id="id11"><span class="brackets">1</span></dt>
<dd><p>A. Simonetto, A. Mokhtari, A. Koppel, G. Leus, and A. Ribeiro,
“A Class of Prediction-Correction Methods for Time-Varying
Convex Optimization,” IEEE Transactions on Signal Processing,
vol. 64, no. 17, pp. 4576–4591, Sep. 2016.</p>
</dd>
</dl>
<dl class="py method">
<dt id="tvopt.costs.DynamicExample_1D.approximate_time_derivative">
<code class="sig-name descname">approximate_time_derivative</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="n">der</span><span class="o">=</span><span class="default_value">'tx'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_1D.approximate_time_derivative" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DynamicExample_1D.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_1D.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DynamicExample_1D.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_1D.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DynamicExample_1D.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_1D.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DynamicExample_1D.time_derivative">
<code class="sig-name descname">time_derivative</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="n">der</span><span class="o">=</span><span class="default_value">'tx'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_1D.time_derivative" title="Permalink to this definition">¶</a></dt>
<dd><p>A derivative w.r.t. time of the cost.</p>
<p>This method computes derivatives w.r.t. time of the cost, or mixed
derivatives w.r.t. both time and x (<em>e.g.</em> the derivative in time of
the gradient).</p>
<p>If this method is not overwritten, it computes the derivative by
default using <em>backward finite differences</em>. See
<cite>backward_finite_difference</cite> for details.</p>
<p>If the cost is static, <span class="math notranslate nohighlight">\(0\)</span> is returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the derivative should be evaluated.</p></li>
<li><p><strong>t</strong> (<em>float</em>) – The time at which the derivative should be evaluated.</p></li>
<li><p><strong>der</strong> (<em>str</em><em>, </em><em>optional</em>) – A sequence of “x” and “t” that chooses which derivative should be
computed. For example, the default “tx” denotes the derivative
w.r.t. time of the cost’s (sub-)gradient.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the number of “x” characters in <cite>der</cite> exceeds <span class="math notranslate nohighlight">\(2\)</span>.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The required derivative or <span class="math notranslate nohighlight">\(0\)</span>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array_like</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.DynamicExample_2D">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">DynamicExample_2D</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t_s</span></em>, <em class="sig-param"><span class="n">t_max</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Bi-dimensional benchmark dynamic cost.</p>
<p>The dynamic cost was propposed in [1]__ and is defined as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(\pmb{x}; t) = \frac{1}{2} (x_1 - \exp(\cos(t)))^2 + \frac{1}{2} (x_2 - x_1 \tanh(t))^2\]</div>
</div></blockquote>
<p>where we used the notation <span class="math notranslate nohighlight">\(\pmb{x} = [x_1, x_2]^\top\)</span>.</p>
<dl class="footnote brackets">
<dt class="label" id="id12"><span class="brackets">1</span></dt>
<dd><p>Y. Zhang, Z. Qi, B. Qiu, M. Yang, and M. Xiao, “Zeroing Neural
Dynamics and Models for Various Time-Varying Problems Solving
with ZLSF Models as Minimization-Type and Euler-Type Special
Cases [Research Frontier],” IEEE Computational Intelligence
Magazine, vol. 14, no. 3, pp. 52–60, Aug. 2019.</p>
</dd>
</dl>
<dl class="py method">
<dt id="tvopt.costs.DynamicExample_2D.approximate_time_derivative">
<code class="sig-name descname">approximate_time_derivative</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="n">der</span><span class="o">=</span><span class="default_value">'tx'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_2D.approximate_time_derivative" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DynamicExample_2D.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_2D.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DynamicExample_2D.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_2D.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DynamicExample_2D.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">t</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_2D.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.DynamicExample_2D.time_derivative">
<code class="sig-name descname">time_derivative</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="n">der</span><span class="o">=</span><span class="default_value">'tx'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.DynamicExample_2D.time_derivative" title="Permalink to this definition">¶</a></dt>
<dd><p>A derivative w.r.t. time of the cost.</p>
<p>This method computes derivatives w.r.t. time of the cost, or mixed
derivatives w.r.t. both time and x (<em>e.g.</em> the derivative in time of
the gradient).</p>
<p>If this method is not overwritten, it computes the derivative by
default using <em>backward finite differences</em>. See
<cite>backward_finite_difference</cite> for details.</p>
<p>If the cost is static, <span class="math notranslate nohighlight">\(0\)</span> is returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the derivative should be evaluated.</p></li>
<li><p><strong>t</strong> (<em>float</em>) – The time at which the derivative should be evaluated.</p></li>
<li><p><strong>der</strong> (<em>str</em><em>, </em><em>optional</em>) – A sequence of “x” and “t” that chooses which derivative should be
computed. For example, the default “tx” denotes the derivative
w.r.t. time of the cost’s (sub-)gradient.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the number of “x” characters in <cite>der</cite> exceeds <span class="math notranslate nohighlight">\(2\)</span>.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The required derivative or <span class="math notranslate nohighlight">\(0\)</span>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array_like</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Huber">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Huber</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em>, <em class="sig-param"><span class="n">threshold</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Vector Huber loss.</p>
<p>The cost is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}f(\pmb{x}) = \begin{cases} \|\pmb{x}\|^2 / 2 &amp; \text{if} \ \|\pmb{x}\| \leq \theta \\
\theta (\|\pmb{x}\| - \theta / 2) &amp; \text{otherwise} \end{cases}\end{split}\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\theta &gt; 0\)</span> is a given threshold.</p>
<dl class="py method">
<dt id="tvopt.costs.Huber.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Huber.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Huber.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Huber.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id13"><span class="problematic" id="id14">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Huber_1D">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Huber_1D</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">threshold</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber_1D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Huber loss.</p>
<p>The cost is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}f(x) = \begin{cases} x^2 / 2 &amp; \text{if} \ |x| \leq \theta \\
\theta (|x| - \theta / 2) &amp; \text{otherwise} \end{cases}\end{split}\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\theta &gt; 0\)</span> is a given threshold.</p>
<dl class="py method">
<dt id="tvopt.costs.Huber_1D.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber_1D.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Huber_1D.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber_1D.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Huber_1D.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber_1D.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Huber_1D.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Huber_1D.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id15"><span class="problematic" id="id16">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Indicator">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Indicator</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">s</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Indicator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Indicator function of a given set.</p>
<p>This objects implements the indicator function of a given <cite>Set</cite> object.
That is, given the set <span class="math notranslate nohighlight">\(\mathbb{S}\)</span> we define:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}f(\pmb{x}) = \begin{cases} 0 &amp; \text{if} \ \pmb{x} \in \mathbb{S} \\
+\infty &amp; \text{otherwise}. \end{cases}\end{split}\]</div>
</div></blockquote>
<p>The proximal operator of the cost is the projection onto the set.</p>
<dl class="py method">
<dt id="tvopt.costs.Indicator.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Indicator.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Indicator.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Indicator.projection" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Indicator.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Indicator.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id17"><span class="problematic" id="id18">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Linear">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Linear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Linear cost.</p>
<p>The function is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(x) = \langle \pmb{x}, \pmb{b} \rangle + c.\]</div>
</div></blockquote>
</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.LinearRegression">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">LinearRegression</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.LinearRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Cost for linear regression.</p>
<p>The cost is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(\pmb{x}) = \frac{1}{2} \| \pmb{A} \pmb{x} - \pmb{b} \|^2.\]</div>
</div></blockquote>
</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Logistic">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Logistic</code><a class="headerlink" href="#tvopt.costs.Logistic" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Logistic function.</p>
<p>The function is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(x) = \log\left( 1 + \exp(x) \right).\]</div>
</div></blockquote>
<dl class="py method">
<dt id="tvopt.costs.Logistic.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Logistic.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Logistic.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Logistic.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Logistic.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Logistic.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Norm_1">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Norm_1</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">weight</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Norm_1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Class for <span class="math notranslate nohighlight">\(\ell_1\)</span> norm.</p>
<p>The function is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(\pmb{x}) = w \| \pmb{x} \|_1\]</div>
</div></blockquote>
<p>for <span class="math notranslate nohighlight">\(\pmb{x} \in \mathbb{R}^n\)</span> and <span class="math notranslate nohighlight">\(w &gt; 0\)</span>.</p>
<dl class="py method">
<dt id="tvopt.costs.Norm_1.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Norm_1.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Norm_1.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Norm_1.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Norm_1.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Norm_1.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>Proximal evaluation of <span class="math notranslate nohighlight">\(\ell_1\)</span> norm, a.k.a. soft-thresholding.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-meth docutils literal notranslate"><span class="pre">utils.soft_thresholding()</span></code></p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Norm_2">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Norm_2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">weight</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Norm_2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Square <span class="math notranslate nohighlight">\(2\)</span>-norm.</p>
</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Norm_inf">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Norm_inf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">weight</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Norm_inf" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Class for <span class="math notranslate nohighlight">\(\ell_\infty\)</span> norm.</p>
<dl class="py method">
<dt id="tvopt.costs.Norm_inf.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Norm_inf.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Norm_inf.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-05</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Norm_inf.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>Proximal evaluation of <span class="math notranslate nohighlight">\(\ell_\infty\)</span> norm.</p>
<p>See [1]__ for the formula.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id19"><span class="brackets">1</span></dt>
<dd><p>A. Beck, First-Order Methods in Optimization. Philadelphia, PA:
Society for Industrial and Applied Mathematics, 2017.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.PowerCost">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">PowerCost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cost</span></em>, <em class="sig-param"><span class="n">p</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.PowerCost" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Power cost.</p>
<p>This class defines a cost as the given power of a cost. It is used for
implementing the <cite>*</cite> operation.</p>
<dl class="py method">
<dt id="tvopt.costs.PowerCost.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.PowerCost.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the power cost.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.PowerCost.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.PowerCost.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the power cost (sub-)gradient.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.PowerCost.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.PowerCost.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the power cost Hessian.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.ProductCost">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">ProductCost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">c_1</span></em>, <em class="sig-param"><span class="n">c_2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ProductCost" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Product of two costs.</p>
<p>This class defines a cost from the product of two given costs. Derivatives
are computed using the chain rule.</p>
<dl class="py method">
<dt id="tvopt.costs.ProductCost.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ProductCost.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the product cost.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.ProductCost.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ProductCost.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the product cost (sub-)gradient.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.ProductCost.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ProductCost.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the product cost Hessian.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Quadratic">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Quadratic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">c</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Quadratic cost.</p>
<p>The function is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(x) = \frac{1}{2} \pmb{x}^\top \pmb{A} \pmb{x} + \langle \pmb{x}, \pmb{b} \rangle + c\]</div>
</div></blockquote>
<p>with the given matrix <span class="math notranslate nohighlight">\(\pmb{A} \in \mathbb{R}^{n \times n}\)</span> and
vector <span class="math notranslate nohighlight">\(\pmb{b} \in \mathbb{R}^n\)</span>.</p>
<dl class="py method">
<dt id="tvopt.costs.Quadratic.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Quadratic.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Quadratic.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Quadratic.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id20"><span class="problematic" id="id21">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.Quadratic_1D">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">Quadratic_1D</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">c</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic_1D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Scalar quadratic cost.</p>
<p>The cost is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(x) = a x^2 / 2 + b x + c.\]</div>
</div></blockquote>
<dl class="py method">
<dt id="tvopt.costs.Quadratic_1D.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic_1D.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Quadratic_1D.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic_1D.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Quadratic_1D.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic_1D.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.Quadratic_1D.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.Quadratic_1D.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id22"><span class="problematic" id="id23">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.RobustLinearRegression">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">RobustLinearRegression</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">threshold</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.RobustLinearRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Cost for robust linear regression.</p>
<p>Let <span class="math notranslate nohighlight">\(h : \mathbb{R} \to \mathbb{R}\)</span> be the Huber loss, then thecost
is defined as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(\pmb{x}) = \sum_{i = 1}^m h(a_i \pmb{x} - b_i)\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(a_i \in \mathbb{R}^{1 \times n}\)</span> are the rows of the data
matrix <span class="math notranslate nohighlight">\(\pmb{A} \in \mathbb{R}^{m \times n}\)</span>, and <span class="math notranslate nohighlight">\(b_i\)</span> the
elements of the data vector <span class="math notranslate nohighlight">\(\pmb{b}\)</span>.</p>
<dl class="py method">
<dt id="tvopt.costs.RobustLinearRegression.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.RobustLinearRegression.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.RobustLinearRegression.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.RobustLinearRegression.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.RobustLinearRegression.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.RobustLinearRegression.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.SampledCost">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">SampledCost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cost</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SampledCost" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Sampled cost.</p>
<p>This class defines a <em>static</em> cost by sampling a <em>dynamic</em> cost at a given
time.</p>
<dl class="py method">
<dt id="tvopt.costs.SampledCost.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SampledCost.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SampledCost.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SampledCost.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SampledCost.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SampledCost.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SampledCost.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SampledCost.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.ScaledCost">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">ScaledCost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cost</span></em>, <em class="sig-param"><span class="n">s</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ScaledCost" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Scaled cost.</p>
<p>This class defines a cost scaled by a constant. That is, given the cost
<span class="math notranslate nohighlight">\(f : \mathbb{R}^n \times \mathbb{R}_+ \to \mathbb{R} \cup \{ +\infty \}\)</span>
and <span class="math notranslate nohighlight">\(c \in \mathbb{R}\)</span> it defines:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[g(\pmb{x}; t) = c f(\pmb{x}; t).\]</div>
</div></blockquote>
<p>The class is used for the product and division by a constant.</p>
<dl class="py method">
<dt id="tvopt.costs.ScaledCost.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ScaledCost.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.ScaledCost.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ScaledCost.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.ScaledCost.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ScaledCost.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.ScaledCost.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.ScaledCost.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id24"><span class="problematic" id="id25">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.SeparableCost">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">SeparableCost</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">costs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SeparableCost" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Separable cost function.</p>
<p>This class defines a separable cost, that is</p>
<div class="math notranslate nohighlight">
\[f(\pmb{x}; t) = \sum_{i = 1}^N f_i(x_i; t)\]</div>
<p>where <span class="math notranslate nohighlight">\(x_i \in \mathbb{R}^{n_1 \times n_2 \times \ldots}\)</span> for each
<span class="math notranslate nohighlight">\(i = 1, \ldots, N\)</span>. Each of the component functions <span class="math notranslate nohighlight">\(f_i\)</span> can
be either static or dynamic. This is useful for defining distributed
optimization problems.</p>
<p>The overall dimension of the domain is
<span class="math notranslate nohighlight">\(n_1 \times n_2 \times \ldots \times N\)</span>, meaning that the last
dimension indexes the components.</p>
<p>The class exposes the same methods as any <cite>Cost</cite>, with the difference that
the keyword argument <cite>i</cite> can be used to evaluate only a single component.
If all components are evaluated, an ndarray is returned with the last
dimension indexing the components.</p>
<p>The class has the <cite>Cost</cite> attributes, with the following additions or
differences.</p>
<dl class="py attribute">
<dt id="tvopt.costs.SeparableCost.costs">
<code class="sig-name descname">costs</code><a class="headerlink" href="#tvopt.costs.SeparableCost.costs" title="Permalink to this definition">¶</a></dt>
<dd><p>The component costs.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.SeparableCost.N">
<code class="sig-name descname">N</code><a class="headerlink" href="#tvopt.costs.SeparableCost.N" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of components.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.SeparableCost.is_dynamic">
<code class="sig-name descname">is_dynamic</code><a class="headerlink" href="#tvopt.costs.SeparableCost.is_dynamic" title="Permalink to this definition">¶</a></dt>
<dd><p>True if at least one component is dynamic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.costs.SeparableCost.smooth">
<code class="sig-name descname">smooth</code><a class="headerlink" href="#tvopt.costs.SeparableCost.smooth" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the minimum of the smoothness degrees of all components.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SeparableCost.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">i</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SeparableCost.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SeparableCost.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">i</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SeparableCost.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SeparableCost.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">i</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SeparableCost.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SeparableCost.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">i</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SeparableCost.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost(s) proximal(s).</p>
<p>This is the same as calling _evaluate with “proximal”, with the
difference that is customized to handle the penalty parameter. In
particular, the penalty can either be a scalar, in which case the same
penalty is used for all components, or a list of component-wise
penalties.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.costs.SumCost">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">SumCost</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">costs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SumCost" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Sum of costs.</p>
<p>This class defines a cost as the sum of an arbitrary number of costs. That
is, given the costs
<span class="math notranslate nohighlight">\(f_i : \mathbb{R}^n \times \mathbb{R}_+ \to \mathbb{R} \cup \{ +\infty \}\)</span>
with <span class="math notranslate nohighlight">\(i = 1, \ldots, N\)</span>, the class defines:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(\pmb{x}; t) = \sum_{i = 1}^N f_i(\pmb{x}; t)\]</div>
</div></blockquote>
<p>The <cite>function</cite>, <cite>gradient</cite> and <cite>hessian</cite> are defined from the components’
methods using the sum rule, while the proximal by default is computed
recursively.</p>
<dl class="py method">
<dt id="tvopt.costs.SumCost.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SumCost.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SumCost.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SumCost.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.costs.SumCost.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.SumCost.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="tvopt.costs.backward_finite_difference">
<code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">backward_finite_difference</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">signal</span></em>, <em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="n">order</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">step</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.backward_finite_difference" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the backward finite difference of a signal.</p>
<p>This function computes an approximate derivative of a given signal using
backward finite differences. Given the signal <span class="math notranslate nohighlight">\(s(t)\)</span>, it computes:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[s^o(t) = \sum_{i = 0}^o (-1)^i {o \choose i} s(t - i T_s) / T_s^o\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(o \in \mathbb{N}\)</span> is the derivative order and <span class="math notranslate nohighlight">\(T_s\)</span> is
the sampling time, see [1]__ for more details.</p>
<p>Notice that if samples before <span class="math notranslate nohighlight">\(t = 0\)</span> are required, they are set to
zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> – A function of a single scalar argument that represents the signal.</p></li>
<li><p><strong>t</strong> (<em>float</em>) – The time where the derivative should be evaluated.</p></li>
<li><p><strong>order</strong> (<em>int</em><em>, </em><em>optional</em>) – The derivative order, defaults to 1.</p></li>
<li><p><strong>step</strong> (<em>float</em><em>, </em><em>optional</em>) – The sampling time, defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – For invalid <cite>order</cite> or <cite>step</cite> arguments.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The approximate derivative.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id26"><span class="brackets">1</span></dt>
<dd><p>A. Quarteroni, R. Sacco, and F. Saleri, Numerical mathematics, 2nd
ed. Berlin; New York: Springer, 2007.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.costs.compute_proximal">
<code class="sig-prename descclassname">tvopt.costs.</code><code class="sig-name descname">compute_proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span></em>, <em class="sig-param"><span class="n">solver</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.costs.compute_proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the proximal of a cost.</p>
<p>This function (approximately) computes the proximal of a given cost if
there is no closed form solution. The function uses either a Newton method
or a gradient method, both with backtracking line search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> (<a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><em>Cost</em></a>) – The static cost whose proximal is required.</p></li>
<li><p><strong>x</strong> (<em>array_like</em>) – Where the proximal has to be evaluated.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The penalty of the proximal.</p></li>
<li><p><strong>solver</strong> (<em>str</em><em>, </em><em>optional</em>) – The method to use for computing the proximal, Newton or gradient. If
not specified, Newton is used for twice differentiable function,
gradient otherwise.</p></li>
<li><p><strong>**kwargs</strong> (<em>dict</em>) – Parameters for the Newton or gradient method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – The proximal.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">solvers.backtracking_gradient()</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">solvers.newton()</span></code></p>
</div>
</dd></dl>

</div>
<div class="section" id="module-tvopt.distributed_solvers">
<span id="tvopt-distributed-solvers-module"></span><h2>tvopt.distributed_solvers module<a class="headerlink" href="#module-tvopt.distributed_solvers" title="Permalink to this headline">¶</a></h2>
<p>Distributed solvers.</p>
<dl class="py function">
<dt id="tvopt.distributed_solvers.admm">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">admm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">penalty</span></em>, <em class="sig-param"><span class="n">rel</span></em>, <em class="sig-param"><span class="n">w_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.admm" title="Permalink to this definition">¶</a></dt>
<dd><p>Distributed relaxed alternating direction method of multipliers (ADMM).</p>
<p>This function implements the distributed ADMM, see <a href="#id53"><span class="problematic" id="id27">[1]_</span></a> and references
therein. The algorithm is characterized by the following updates</p>
<div class="math notranslate nohighlight">
\[x_i^\ell = \operatorname{prox}_{f_i / (\rho d_i)}
([\pmb{A}^\top z^\ell]_i / (\rho d_i))\]</div>
<div class="math notranslate nohighlight">
\[z_{ij}^{\ell+1} = (1-\alpha) z_{ij}^\ell - \alpha z_{ji}^\ell
+ 2 \alpha \rho x_j^\ell\]</div>
<p>for <span class="math notranslate nohighlight">\(\ell = 0, 1, \ldots\)</span>, where <span class="math notranslate nohighlight">\(d_i\)</span> is node <span class="math notranslate nohighlight">\(i\)</span>’s
degree, <span class="math notranslate nohighlight">\(\rho\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span> are the penalty and relaxation
parameters, and <span class="math notranslate nohighlight">\(\pmb{A}\)</span> is the arc incidence matrix. The algorithm
is guaranteed to converge to the optimal solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – A dictionary containing the network describing the multi-agent system
and the cost describing the problem.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The penalty parameter <span class="math notranslate nohighlight">\(\rho\)</span> of the algorithm (convergence is
guaranteed for any positive value).</p></li>
<li><p><strong>rel</strong> (<em>float</em>) – The relaxation parameter <span class="math notranslate nohighlight">\(\alpha\)</span> of the algorithm (convergence
is guaranteed for values in <span class="math notranslate nohighlight">\((0,1)\)</span>).</p></li>
<li><p><strong>w_0</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The initial value of the dual nodes’ states. This can be either an
ndarray of suitable size with the last dimension indexing the nodes, or
a scalar. If it is a scalar then the same initial value is used for
all components.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The nodes’ states after <cite>num_iter</cite> iterations.</p></li>
<li><p><strong>w</strong> (<em>ndarray</em>) – The dual variables of the nodes after <cite>num_iter</cite> iterations.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id28"><span class="brackets">1</span></dt>
<dd><p>N. Bastianello, R. Carli, L. Schenato, and M. Todescato,
“Asynchronous Distributed Optimization over Lossy Networks via
Relaxed ADMM: Stability and Linear Convergence,” IEEE Transactions
on Automatic Control.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.aug_dgm">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">aug_dgm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.aug_dgm" title="Permalink to this definition">¶</a></dt>
<dd><p>Augmented distributed gradient method (Aug-DGM).</p>
<p>This function implements the Aug-DGM algorithm (see <a href="#id54"><span class="problematic" id="id29">[1]_</span></a>). The algorithm is
characterized by the following updates</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{y}^\ell &amp;= \pmb{W} \left( \pmb{y}^{\ell-1}
              + \nabla f(\pmb{x}^\ell) - \nabla f(\pmb{x}^{\ell-1}) \right) \\
\pmb{x}^{\ell+1} &amp;= \pmb{W} \left( \pmb{x}^\ell - \pmb{A} \pmb{y}^\ell \right)
\end{align}\end{split}\]</div>
<p>for <span class="math notranslate nohighlight">\(\ell = 0, 1, \ldots\)</span> where <span class="math notranslate nohighlight">\(\pmb{A}\)</span> is a diagonal matrix
of uncoordinated step-sizes. The algorithm is guaranteed to converge
to the optimal solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – A dictionary containing the network describing the multi-agent system
and the cost describing the problem.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – A common step-size or a list of local step-sizes, one for each node.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The initial states of the nodes. This can be either an ndarray
of suitable size with the last dimension indexing the nodes, or
a scalar. If it is a scalar then the same initial value is used for
all components of the states.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id30"><span class="brackets">1</span></dt>
<dd><p>J. Xu, S. Zhu, Y. C. Soh, and L. Xie, “Augmented distributed
gradient methods for multi-agent optimization under uncoordinated
constant stepsizes,” in 2015 54th IEEE Conference on Decision and
Control (CDC), Osaka, Japan, Dec. 2015, pp. 2055–2060.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.average_consensus">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">average_consensus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">x_0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.average_consensus" title="Permalink to this definition">¶</a></dt>
<dd><p>Average consensus.</p>
<p>Compute the average consensus over the network <cite>net</cite> with initial
states <cite>x_0</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network"><em>networks.Network</em></a>) – The network describing the multi-agent system.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em>) – The initial states in a ndarray, with the last dimension indexing the
nodes.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.dpgm">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">dpgm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.dpgm" title="Permalink to this definition">¶</a></dt>
<dd><p>Distributed proximal gradient method (DPGM).</p>
<p>This function implements the DPGM algorithm proposed in <a href="#id55"><span class="problematic" id="id31">[1]_</span></a> (see also
<a href="#id56"><span class="problematic" id="id32">[2]_</span></a> for the gradient-only version). The algorithm is characterized by
the following updates</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{y}^\ell &amp;= \pmb{W} \pmb{x}^\ell - \alpha \nabla f(\pmb{x}^\ell) \\
\pmb{x}^{\ell+1} &amp;= \operatorname{prox}_{\alpha g}(\pmb{y}^\ell)
\end{align}\end{split}\]</div>
<p>for <span class="math notranslate nohighlight">\(\ell = 0, 1, \ldots\)</span>. The algorithm is guaranteed to converge
to a neighborhood of the optimal solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – A dictionary containing the network describing the multi-agent system
and the costs describing the (possibly composite) problem. The
dictionary should contain <span class="math notranslate nohighlight">\(f\)</span> and the network, and optionally
<span class="math notranslate nohighlight">\(g\)</span>.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – The step-size.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The initial states of the nodes. This can be either an ndarray
of suitable size with the last dimension indexing the nodes, or
a scalar. If it is a scalar then the same initial value is used for
all components of the states.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id33"><span class="brackets">1</span></dt>
<dd><p>Bastianello, N., Ajalloeian, A., &amp; Dall’Anese, E. (2020).
Distributed and Inexact Proximal Gradient Method for Online Convex
Optimization. arXiv preprint arXiv:2001.00870.</p>
</dd>
<dt class="label" id="id34"><span class="brackets">2</span></dt>
<dd><p>Yuan, K., Ling, Q., &amp; Yin, W. (2016). On the convergence of
decentralized gradient descent. SIAM Journal on Optimization,
26(3), 1835-1854.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.dual_ascent">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">dual_ascent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">w_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.dual_ascent" title="Permalink to this definition">¶</a></dt>
<dd><p>Distributed dual ascent a.k.a. dual decomposition (DD).</p>
<p>This function implements the DD algorithm <a href="#id57"><span class="problematic" id="id35">[1]_</span></a>. The algorithm is
characterized by the following updates</p>
<div class="math notranslate nohighlight">
\[\pmb{x}^\ell = \operatorname{arg\,min}_{\pmb{x}} \left\{
f(\pmb{x}) - \langle (\pmb{I} - \pmb{W}) \pmb{x}, \pmb{w}^\ell
\rangle\right\}\]</div>
<div class="math notranslate nohighlight">
\[\pmb{w}^{\ell+1} = \pmb{w}^\ell
- \alpha (\pmb{I} - \pmb{W}) \pmb{x}^\ell\]</div>
<p>for <span class="math notranslate nohighlight">\(\ell = 0, 1, \ldots\)</span>, where <span class="math notranslate nohighlight">\(\pmb{w}\)</span> is the vector of
Lagrange multipliers. The algorithm is guaranteed to converge to the
optimal solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary containing the network describing the multi-agent system</strong> (<em>A</em>) – and the cost describing the problem.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – The step-size.</p></li>
<li><p><strong>w_0</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The initial value of the dual nodes’ states. This can be either an
ndarray of suitable size with the last dimension indexing the nodes, or
a scalar. If it is a scalar then the same initial value is used for
all components.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The nodes’ states after <cite>num_iter</cite> iterations.</p></li>
<li><p><strong>w</strong> (<em>ndarray</em>) – The dual variables of the nodes after <cite>num_iter</cite> iterations.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id36"><span class="brackets">1</span></dt>
<dd><p>Simonetto, A. (2018). Dual Prediction–Correction Methods for
Linearly Constrained Time-Varying Convex Programs. IEEE Transactions
on Automatic Control, 64(8), 3355-3361.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.gossip_consensus">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">gossip_consensus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">x_0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">q</span><span class="o">=</span><span class="default_value">0.5</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.gossip_consensus" title="Permalink to this definition">¶</a></dt>
<dd><p>Average consensus.</p>
<p>Compute the average consensus over the network <cite>net</cite> with initial
states <cite>x_0</cite> using the symmetric gossip protocol.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network"><em>networks.Network</em></a>) – The network describing the multi-agent system.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em>) – The initial states in a ndarray, with the last dimension indexing the
nodes.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>q</strong> (<em>float</em><em>, </em><em>optional</em>) – The weight used in the convex combination of the nodes that
communicate at each iteration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.max_consensus">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">max_consensus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">x_0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.max_consensus" title="Permalink to this definition">¶</a></dt>
<dd><p>Max consensus.</p>
<p>Compute the maximum of the nodes’ states <cite>x_0</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network"><em>networks.Network</em></a>) – The network describing the multi-agent system.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em>) – The initial states in a ndarray, with the last dimension indexing the
nodes.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.nids">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">nids</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.nids" title="Permalink to this definition">¶</a></dt>
<dd><p>Network InDependent Step-size algorithm (NIDS).</p>
<p>This function implements the NIDS algorithm proposed in <a href="#id58"><span class="problematic" id="id37">[1]_</span></a>. The algorithm
is characterized by the following updates</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{y}^\ell &amp;= \pmb{y}^{\ell-1} - \pmb{x}^\ell
- \tilde{\pmb{W}} (2 \pmb{x}^\ell - \pmb{x}^{\ell-1}
- \operatorname{diag}(\pmb{\alpha}) (\nabla f(\pmb{x}^\ell)
- \nabla f(\pmb{x}^{\ell-1}))) \\
\pmb{x}^{\ell+1} &amp;= \operatorname{prox}_{\pmb{\alpha} g}(\pmb{y}^\ell)
\end{align}\end{split}\]</div>
<p>for <span class="math notranslate nohighlight">\(\ell = 0, 1, \ldots\)</span>, where <span class="math notranslate nohighlight">\(\pmb{\alpha}\)</span> is a column
vector containing the independent step-sizes of the nodes, and</p>
<div class="math notranslate nohighlight">
\[\tilde{\pmb{W}} = \pmb{I}
+ c \operatorname{diag}(\pmb{\alpha}) (\pmb{W} - \pmb{I})\]</div>
<p>with <span class="math notranslate nohighlight">\(c = 0.5 / \max_i \{ \alpha_i \}\)</span>. The algorithm is guaranteed
to converge to the optimal solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – A dictionary containing the network describing the multi-agent system
and the costs describing the (possibly composite) problem. The
dictionary should contain <span class="math notranslate nohighlight">\(f\)</span> and the network, and optionally
<span class="math notranslate nohighlight">\(g\)</span>.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – A common step-size or a list of local step-sizes, one for each node.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The initial states of the nodes. This can be either an ndarray
of suitable size with the last dimension indexing the nodes, or
a scalar. If it is a scalar then the same initial value is used for
all components of the states.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id38"><span class="brackets">1</span></dt>
<dd><p>Li, Z., Shi, W., &amp; Yan, M. (2019). A decentralized proximal-gradient
method with network independent step-sizes and separated convergence
rates. IEEE Transactions on Signal Processing, 67(17), 4494-4506.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.pg_extra">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">pg_extra</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.pg_extra" title="Permalink to this definition">¶</a></dt>
<dd><p>Proximal gradient exact first-order algorithm (PG-EXTRA).</p>
<p>This function implements the PG-EXTRA algorithm proposed in <a href="#id59"><span class="problematic" id="id39">[1]_</span></a> (see also
<a href="#id60"><span class="problematic" id="id40">[2]_</span></a> for the gradient-only version, EXTRA). The algorithm is characterized
by the following updates</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{y}^\ell &amp;= \pmb{y}^{\ell-1} + \pmb{W} \pmb{x}^\ell
             - \tilde{\pmb{W}} \pmb{x}^{\ell-1}
             - \alpha (\nabla f(\pmb{x}^\ell) - \nabla f(\pmb{x}^{\ell-1})) \\
\pmb{x}^{\ell+1} &amp;= \operatorname{prox}_{\alpha g}(\pmb{y}^\ell)
\end{align}\end{split}\]</div>
<p>for <span class="math notranslate nohighlight">\(\ell = 0, 1, \ldots\)</span>, where
<span class="math notranslate nohighlight">\(\tilde{\pmb{W}} = (\pmb{I} + \pmb{W}) /2\)</span>. The
algorithm is guaranteed to converge to the optimal solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – A dictionary containing the network describing the multi-agent system
and the costs describing the (possibly composite) problem. The
dictionary should contain <span class="math notranslate nohighlight">\(f\)</span> and the network, and optionally
<span class="math notranslate nohighlight">\(g\)</span>.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – The step-size.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The initial states of the nodes. This can be either an ndarray
of suitable size with the last dimension indexing the nodes, or
a scalar. If it is a scalar then the same initial value is used for
all components of the states.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id41"><span class="brackets">1</span></dt>
<dd><p>Shi, W., Ling, Q., Wu, G., &amp; Yin, W. (2015). A proximal gradient
algorithm for decentralized composite optimization. IEEE
Transactions on Signal Processing, 63(22), 6013-6023.</p>
</dd>
<dt class="label" id="id42"><span class="brackets">2</span></dt>
<dd><p>Shi, W., Ling, Q., Wu, G., &amp; Yin, W. (2015). Extra: An exact
first-order algorithm for decentralized consensus optimization.
SIAM Journal on Optimization, 25(2), 944-966.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.prox_ed">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">prox_ed</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.prox_ed" title="Permalink to this definition">¶</a></dt>
<dd><p>Proximal exact diffusion (Prox-ED).</p>
<p>This function implements the Prox-ED algorithm <a href="#id61"><span class="problematic" id="id43">[1]_</span></a>. The algorithm is
characterized by the following updates</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{y}^\ell &amp;= \pmb{x}^\ell - \alpha \nabla f(\pmb{x}^\ell) \\
\pmb{u}^\ell &amp;= \pmb{z}^{\ell-1} + \pmb{y}^\ell - \pmb{y}^{\ell-1} \\
\pmb{z}^\ell &amp;= \tilde{\pmb{W}} \pmb{u}^\ell \\
\pmb{x}^{\ell+1} &amp;= \operatorname{prox}_{\alpha g}(\pmb{z}^\ell)
\end{align}\end{split}\]</div>
<p>for <span class="math notranslate nohighlight">\(\ell = 0, 1, \ldots\)</span>, where
<span class="math notranslate nohighlight">\(\tilde{\pmb{W}} = (\pmb{I} + \pmb{W}) /2\)</span>. The
algorithm is guaranteed to converge to the optimal solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – A dictionary containing the network describing the multi-agent system
and the costs describing the (possibly composite) problem. The
dictionary should contain <span class="math notranslate nohighlight">\(f\)</span> and the network, and optionally
<span class="math notranslate nohighlight">\(g\)</span>.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – The step-size.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The initial states of the nodes. This can be either an ndarray
of suitable size with the last dimension indexing the nodes, or
a scalar. If it is a scalar then the same initial value is used for
all components of the states.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id44"><span class="brackets">1</span></dt>
<dd><p>S. A. Alghunaim, E. Ryu, K. Yuan, and A. H. Sayed, “Decentralized
Proximal Gradient Algorithms with Linear Convergence Rates,” IEEE
Transactions on Automatic Control, 2020.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.distributed_solvers.ratio_consensus">
<code class="sig-prename descclassname">tvopt.distributed_solvers.</code><code class="sig-name descname">ratio_consensus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">x_0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.distributed_solvers.ratio_consensus" title="Permalink to this definition">¶</a></dt>
<dd><p>Ratio consensus.</p>
<p>Compute the average consensus over the network <cite>net</cite> with initial
states <cite>x_0</cite> using the ratio consensus protocol.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network"><em>networks.Network</em></a>) – The network describing the multi-agent system.</p></li>
<li><p><strong>x_0</strong> (<em>ndarray</em>) – The initial states in a ndarray, with the last dimension indexing the
nodes.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The nodes’ states after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-tvopt.networks">
<span id="tvopt-networks-module"></span><h2>tvopt.networks module<a class="headerlink" href="#module-tvopt.networks" title="Permalink to this headline">¶</a></h2>
<p>Network tools.</p>
<dl class="py class">
<dt id="tvopt.networks.DynamicNetwork">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">DynamicNetwork</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nets</span></em>, <em class="sig-param"><span class="n">t_s</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.DynamicNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.networks.Network</span></code></a></p>
<p>Time-varying network.</p>
<p>This class creates a time-varying network from a list of network objects,
and possibly a sampling time that specifies how often the network changes.</p>
<dl class="py method">
<dt id="tvopt.networks.DynamicNetwork.broadcast">
<code class="sig-name descname">broadcast</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.DynamicNetwork.broadcast" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast transmission.</p>
<p>This method implements a broadcast transmission in which a node sends
the same packet to all its neighbors. The packet is also transmitted
to the node itself. The method is implemented using the <cite>send</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sender</strong> (<em>int</em>) – The index of the transmitting node.</p></li>
<li><p><strong>packet</strong> (<em>array_like</em>) – The packet to ne communicated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.DynamicNetwork.consensus">
<code class="sig-name descname">consensus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.DynamicNetwork.consensus" title="Permalink to this definition">¶</a></dt>
<dd><p>Consensus mixing.</p>
<p>This method implements a consensus step over the network, mixing the
given nodes’ states using the weight matrix of the network or a
different one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The nodes’ local states in an array with the last dimension
indexing the nodes.</p></li>
<li><p><strong>weights</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The consensus weight matrix to be used instead of the one created
at initialization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – The local states after a consensus step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.DynamicNetwork.max_consensus">
<code class="sig-name descname">max_consensus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.DynamicNetwork.max_consensus" title="Permalink to this definition">¶</a></dt>
<dd><p>Max-consensus.</p>
<p>This method implements a step of max-consensus, where each node selects
the (element-wise) maximum between the packets received from its
neighbors and its own state. See [1]__ for a reference on
max-consensus.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – The nodes’ local states in an array with the last dimension
indexing the nodes.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The local states after a max-consensus step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id45"><span class="brackets">1</span></dt>
<dd><p>F. Iutzeler, P. Ciblat, and J. Jakubowicz, “Analysis of
Max-Consensus Algorithms in Wireless Channels,” IEEE
Transactions on Signal Processing, vol. 60, no. 11, pp.
6103–6107, Nov. 2012.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.DynamicNetwork.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.DynamicNetwork.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample the dynamic network.</p>
<p>This method returns the network object that is active at time <cite>t</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> (<em>float</em>) – The time when the network should be sampled.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The sampled network.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network">Network</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.DynamicNetwork.send">
<code class="sig-name descname">send</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.DynamicNetwork.send" title="Permalink to this definition">¶</a></dt>
<dd><p>Node-to-node transmission (sender phase).</p>
<p>This method simulates a node-to-node transmission by storing the packet
to be communicated in the <cite>buffer</cite>. In particular, if <span class="math notranslate nohighlight">\(i\)</span> is the
sender and <span class="math notranslate nohighlight">\(j\)</span> the receiver, then the packet is introduced in
<cite>buffer</cite> with keyword <span class="math notranslate nohighlight">\((j,i)\)</span>.</p>
<p>Note that older information (if any) in the <cite>buffer</cite> is overwritten
whenever <cite>send</cite> is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sender</strong> (<em>int</em>) – The index of the transmitting node.</p></li>
<li><p><strong>receiver</strong> (<em>int</em>) – The index of the recipient.</p></li>
<li><p><strong>packet</strong> (<em>array_like</em>) – The packet to ne communicated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.networks.LossyNetwork">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">LossyNetwork</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">adj_mat</span></em>, <em class="sig-param"><span class="n">loss_prob</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.LossyNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.networks.Network</span></code></a></p>
<p>Network with random communication failures.</p>
<p>Representation of a connected, undirected network, whose communication
protocol is subject to packet losses. Packet sent from a node to another
may be lost with a certain probability.</p>
<dl class="py method">
<dt id="tvopt.networks.LossyNetwork.send">
<code class="sig-name descname">send</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sender</span></em>, <em class="sig-param"><span class="n">receiver</span></em>, <em class="sig-param"><span class="n">packet</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.LossyNetwork.send" title="Permalink to this definition">¶</a></dt>
<dd><p>Node-to-node transmission (sender phase).</p>
<p>This method simulates a node-to-node transmission by storing the packet
to be communicated in the <cite>buffer</cite>. In particular, if <span class="math notranslate nohighlight">\(i\)</span> is the
sender and <span class="math notranslate nohighlight">\(j\)</span> the receiver, then the packet is introduced in
<cite>buffer</cite> with keyword <span class="math notranslate nohighlight">\((j,i)\)</span>.</p>
<p>Note that older information (if any) in the <cite>buffer</cite> is overwritten
whenever <cite>send</cite> is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sender</strong> (<em>int</em>) – The index of the transmitting node.</p></li>
<li><p><strong>receiver</strong> (<em>int</em>) – The index of the recipient.</p></li>
<li><p><strong>packet</strong> (<em>array_like</em>) – The packet to ne communicated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.networks.Network">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">Network</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">adj_mat</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.Network" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Representation of an undirected network.</p>
<p>The class implements an undirected network defined from the adjacency
matrix. The class provides methods for different communication protocols,
such as node-to-node and broadcast.</p>
<p>Transmissions are implemented via the <cite>buffer</cite> attribute of the network:
the sender stores the packet to be transmitted in the <cite>buffer</cite> dictionary,
specifying the recipient, which can then access the packet.</p>
<p>By convention, the nodes in the network are indexed from <span class="math notranslate nohighlight">\(0\)</span> to
<span class="math notranslate nohighlight">\(N-1\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the total number of nodes.</p>
<dl class="py attribute">
<dt id="tvopt.networks.Network.adj_mat">
<code class="sig-name descname">adj_mat</code><a class="headerlink" href="#tvopt.networks.Network.adj_mat" title="Permalink to this definition">¶</a></dt>
<dd><p>The adjacency matrix of the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.networks.Network.N">
<code class="sig-name descname">N</code><a class="headerlink" href="#tvopt.networks.Network.N" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of nodes in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.networks.Network.weights">
<code class="sig-name descname">weights</code><a class="headerlink" href="#tvopt.networks.Network.weights" title="Permalink to this definition">¶</a></dt>
<dd><p>The consensus weight matrix, if not specified in the constructor
this is the Metropolis-Hastings weight matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.networks.Network.neighbors">
<code class="sig-name descname">neighbors</code><a class="headerlink" href="#tvopt.networks.Network.neighbors" title="Permalink to this definition">¶</a></dt>
<dd><p>A list whose <span class="math notranslate nohighlight">\(i\)</span>-th element is a list of node <span class="math notranslate nohighlight">\(i\)</span>’s
neighors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.networks.Network.degrees">
<code class="sig-name descname">degrees</code><a class="headerlink" href="#tvopt.networks.Network.degrees" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of neighbors of each node.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.networks.Network.buffer">
<code class="sig-name descname">buffer</code><a class="headerlink" href="#tvopt.networks.Network.buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>The dictionary used for node-to-node transmissions.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.Network.broadcast">
<code class="sig-name descname">broadcast</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sender</span></em>, <em class="sig-param"><span class="n">packet</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.Network.broadcast" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast transmission.</p>
<p>This method implements a broadcast transmission in which a node sends
the same packet to all its neighbors. The packet is also transmitted
to the node itself. The method is implemented using the <cite>send</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sender</strong> (<em>int</em>) – The index of the transmitting node.</p></li>
<li><p><strong>packet</strong> (<em>array_like</em>) – The packet to ne communicated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.Network.consensus">
<code class="sig-name descname">consensus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.Network.consensus" title="Permalink to this definition">¶</a></dt>
<dd><p>Consensus mixing.</p>
<p>This method implements a consensus step over the network, mixing the
given nodes’ states using the weight matrix of the network or a
different one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The nodes’ local states in an array with the last dimension
indexing the nodes.</p></li>
<li><p><strong>weights</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – The consensus weight matrix to be used instead of the one created
at initialization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – The local states after a consensus step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.Network.max_consensus">
<code class="sig-name descname">max_consensus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.Network.max_consensus" title="Permalink to this definition">¶</a></dt>
<dd><p>Max-consensus.</p>
<p>This method implements a step of max-consensus, where each node selects
the (element-wise) maximum between the packets received from its
neighbors and its own state. See [1]__ for a reference on
max-consensus.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – The nodes’ local states in an array with the last dimension
indexing the nodes.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The local states after a max-consensus step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id46"><span class="brackets">1</span></dt>
<dd><p>F. Iutzeler, P. Ciblat, and J. Jakubowicz, “Analysis of
Max-Consensus Algorithms in Wireless Channels,” IEEE
Transactions on Signal Processing, vol. 60, no. 11, pp.
6103–6107, Nov. 2012.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.Network.receive">
<code class="sig-name descname">receive</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">receiver</span></em>, <em class="sig-param"><span class="n">sender</span></em>, <em class="sig-param"><span class="n">default</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">destructive</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.Network.receive" title="Permalink to this definition">¶</a></dt>
<dd><p>Node-to-node transmission (receiver phase).</p>
<p>This method simulates the reception of a packet previously transmitted
using the <cite>send</cite> method. In patricular, the method accesses the
packet in the <cite>buffer</cite> dictionary. If the packet is not present,
a default value is returned.</p>
<p>Reads from the <cite>buffer</cite> can be destructive, meaning that the packet
is read and removed, which is the default, or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>receiver</strong> (<em>int</em>) – The index of the recipient.</p></li>
<li><p><strong>sender</strong> (<em>int</em>) – The index of the transmitting node.</p></li>
<li><p><strong>default</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The value returned when a packet from <cite>sender</cite> to <cite>receiver</cite> is not
found in the <cite>buffer</cite>.</p></li>
<li><p><strong>destructive</strong> (<em>bool</em><em>, </em><em>optional</em>) – Specifies if the packet should be removed from the <cite>buffer</cite> after
being read (which is the default) or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The packet or a default value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.networks.Network.send">
<code class="sig-name descname">send</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sender</span></em>, <em class="sig-param"><span class="n">receiver</span></em>, <em class="sig-param"><span class="n">packet</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.Network.send" title="Permalink to this definition">¶</a></dt>
<dd><p>Node-to-node transmission (sender phase).</p>
<p>This method simulates a node-to-node transmission by storing the packet
to be communicated in the <cite>buffer</cite>. In particular, if <span class="math notranslate nohighlight">\(i\)</span> is the
sender and <span class="math notranslate nohighlight">\(j\)</span> the receiver, then the packet is introduced in
<cite>buffer</cite> with keyword <span class="math notranslate nohighlight">\((j,i)\)</span>.</p>
<p>Note that older information (if any) in the <cite>buffer</cite> is overwritten
whenever <cite>send</cite> is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sender</strong> (<em>int</em>) – The index of the transmitting node.</p></li>
<li><p><strong>receiver</strong> (<em>int</em>) – The index of the recipient.</p></li>
<li><p><strong>packet</strong> (<em>array_like</em>) – The packet to ne communicated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.networks.NoisyNetwork">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">NoisyNetwork</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">adj_mat</span></em>, <em class="sig-param"><span class="n">noise_var</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.NoisyNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.networks.Network</span></code></a></p>
<p>Network with Gaussian communication noise.</p>
<p>Representation of a connected, undirected network, whose communication
protocol is subject to additive white Gaussian noise. The network’s
transmission methods add normal noise to all packets (unless they are sent
from a node to itself).</p>
<dl class="py method">
<dt id="tvopt.networks.NoisyNetwork.send">
<code class="sig-name descname">send</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sender</span></em>, <em class="sig-param"><span class="n">receiver</span></em>, <em class="sig-param"><span class="n">packet</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.NoisyNetwork.send" title="Permalink to this definition">¶</a></dt>
<dd><p>Node-to-node transmission (sender phase).</p>
<p>This method simulates a node-to-node transmission by storing the packet
to be communicated in the <cite>buffer</cite>. In particular, if <span class="math notranslate nohighlight">\(i\)</span> is the
sender and <span class="math notranslate nohighlight">\(j\)</span> the receiver, then the packet is introduced in
<cite>buffer</cite> with keyword <span class="math notranslate nohighlight">\((j,i)\)</span>.</p>
<p>Note that older information (if any) in the <cite>buffer</cite> is overwritten
whenever <cite>send</cite> is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sender</strong> (<em>int</em>) – The index of the transmitting node.</p></li>
<li><p><strong>receiver</strong> (<em>int</em>) – The index of the recipient.</p></li>
<li><p><strong>packet</strong> (<em>array_like</em>) – The packet to ne communicated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.networks.QuantizedNetwork">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">QuantizedNetwork</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">adj_mat</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">thresholds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.QuantizedNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.networks.Network" title="tvopt.networks.Network"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.networks.Network</span></code></a></p>
<p>Network with quantized communications.</p>
<p>Representation of a connected, undirected network, whose communications
are quantized. The network’s transmission methods quantize all packets
(unless they are sent from a node to itself).</p>
<dl class="py method">
<dt id="tvopt.networks.QuantizedNetwork.send">
<code class="sig-name descname">send</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sender</span></em>, <em class="sig-param"><span class="n">receiver</span></em>, <em class="sig-param"><span class="n">packet</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.QuantizedNetwork.send" title="Permalink to this definition">¶</a></dt>
<dd><p>Node-to-node transmission (sender phase).</p>
<p>This method simulates a node-to-node transmission by storing the packet
to be communicated in the <cite>buffer</cite>. In particular, if <span class="math notranslate nohighlight">\(i\)</span> is the
sender and <span class="math notranslate nohighlight">\(j\)</span> the receiver, then the packet is introduced in
<cite>buffer</cite> with keyword <span class="math notranslate nohighlight">\((j,i)\)</span>.</p>
<p>Note that older information (if any) in the <cite>buffer</cite> is overwritten
whenever <cite>send</cite> is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sender</strong> (<em>int</em>) – The index of the transmitting node.</p></li>
<li><p><strong>receiver</strong> (<em>int</em>) – The index of the recipient.</p></li>
<li><p><strong>packet</strong> (<em>array_like</em>) – The packet to ne communicated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.circle_graph">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">circle_graph</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.circle_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a circle graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>N</strong> (<em>int</em>) – Number of nodes in the graph.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>adj_mat</strong> – Adjacency matrix of the generated graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#tvopt.networks.circulant_graph" title="tvopt.networks.circulant_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">circulant_graph()</span></code></a></dt><dd><p>Circulant graph generator</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.circulant_graph">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">circulant_graph</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em>, <em class="sig-param"><span class="n">num_conn</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.circulant_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a circulant graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<em>int</em>) – Number of nodes in the graph.</p></li>
<li><p><strong>num_conn</strong> (<em>int</em>) – Number of neighbors on each side of a node.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>adj_mat</strong> – Adjacency matrix of the generated graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>If <cite>num_conn</cite> is larger than <cite>N</cite> / 2 a complete graph is returned.</p>
</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.complete_graph">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">complete_graph</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.complete_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a complete graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>N</strong> (<em>int</em>) – Number of nodes in the graph.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>adj_mat</strong> – Adjacency matrix of the generated graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#tvopt.networks.circulant_graph" title="tvopt.networks.circulant_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">circulant_graph()</span></code></a></dt><dd><p>Circulant graph generator</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.erdos_renyi">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">erdos_renyi</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em>, <em class="sig-param"><span class="n">prob</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.erdos_renyi" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a random Erdos-Renyi graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<em>int</em>) – Number of nodes in the graph.</p></li>
<li><p><strong>prob</strong> (<em>float</em>) – The probability of adding an edge between any two nodes.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>adj_mat</strong> – Adjacency matrix of the generated graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError.</strong> – </p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.incidence_matrix">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">incidence_matrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">adj_mat</span></em>, <em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.incidence_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Build the incidence matrix.</p>
<p>The edges <span class="math notranslate nohighlight">\(e = (i,j)\)</span> are ordered with <span class="math notranslate nohighlight">\(i \leq j\)</span>, so that
in the <span class="math notranslate nohighlight">\(e\)</span>-th column the <span class="math notranslate nohighlight">\(i\)</span>-th element is <span class="math notranslate nohighlight">\(1\)</span> and
the <span class="math notranslate nohighlight">\(j\)</span>-th is <span class="math notranslate nohighlight">\(-1\)</span> (the remaining are of course <span class="math notranslate nohighlight">\(0\)</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>adj_mat</strong> (<em>ndarray</em>) – Adjacency matrix describing the graph.</p></li>
<li><p><strong>n</strong> (<em>int</em><em>, </em><em>optional</em>) – Size of the local states.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>incid_mat</strong> – The incidence matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.is_connected">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">is_connected</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">adj_mat</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.is_connected" title="Permalink to this definition">¶</a></dt>
<dd><p>Verify if a graph is connected.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>adj_mat</strong> (<em>ndarray</em>) – Adjacency matrix describing the graph.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if the graph is connected, False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The connectedness of the graph is checked by verifying whether the
<span class="math notranslate nohighlight">\(N\)</span>-th power of the adjacency matrix plus the identity is a full
matrix (no zero elements), with <span class="math notranslate nohighlight">\(N\)</span> the number of nodes.</p>
</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.metropolis_hastings">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">metropolis_hastings</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">adj_mat</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.metropolis_hastings" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute a consensus matrix based on the Metropolis-Hastings rule.</p>
<p>The Metropolis-Hastings rule generates a matrix <span class="math notranslate nohighlight">\(W\)</span> with off-diagonal
elements equal to:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[w_{ij} = \frac{1}{1 + \max\{ d_i, d_j \}}\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(i\)</span> is a node index and <span class="math notranslate nohighlight">\(j \neq i\)</span> the index of one of
its neighbors, and <span class="math notranslate nohighlight">\(d_i\)</span>, <span class="math notranslate nohighlight">\(d_j\)</span> are their respective degrees.
The diagonal elements are assigned as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[w_{ii} = 1 - \sum_{j \in \mathcal{N}_i} w_{ij}\]</div>
</div></blockquote>
<p>to guarantee double stochasticity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>adj_mat</strong> (<em>ndarray</em>) – Adjacency matrix describing the graph.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>mh_mat</strong> – Metropolois-Hastings consensus matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.random_graph">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">random_graph</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em>, <em class="sig-param"><span class="n">radius</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.random_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a random geometric graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<em>int</em>) – Number of nodes in the graph.</p></li>
<li><p><strong>radius</strong> (<em>float</em>) – Radius of each node’s neighborhood, must be in <span class="math notranslate nohighlight">\([0,1)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>adj_mat</strong> – Adjacency matrix of the generated graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError.</strong> – </p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The function recursively generates random positions for the nodes on the
<span class="math notranslate nohighlight">\([0,1] \times [0,1]\)</span> square, and then builds the graph by setting
as neighbors each pair of nodes within a distance no larger than <cite>radius</cite>.
The process is repeated until the result is a connected graph. For this
reason, combinations of small <cite>N</cite> and <cite>radius</cite> <em>can yield
exceedingly long computation times</em>. If the computation does not succeed
after <cite>2500</cite> iterations, an error is raised.</p>
</dd></dl>

<dl class="py function">
<dt id="tvopt.networks.star_graph">
<code class="sig-prename descclassname">tvopt.networks.</code><code class="sig-name descname">star_graph</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.networks.star_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a star graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>N</strong> (<em>int</em>) – Number of nodes in the graph.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>adj_mat</strong> – Adjacency matrix of the generated graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-tvopt.prediction">
<span id="tvopt-prediction-module"></span><h2>tvopt.prediction module<a class="headerlink" href="#module-tvopt.prediction" title="Permalink to this headline">¶</a></h2>
<p>Cost prediction tools.</p>
<dl class="py class">
<dt id="tvopt.prediction.ExtrapolationPrediction">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.prediction.</code><code class="sig-name descname">ExtrapolationPrediction</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cost</span></em>, <em class="sig-param"><span class="n">order</span><span class="o">=</span><span class="default_value">2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.ExtrapolationPrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.prediction.Prediction" title="tvopt.prediction.Prediction"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.prediction.Prediction</span></code></a></p>
<p>Extrapolation-based prediction.</p>
<p>This prediction strategy, proposed in [1]__, predicts the cost at time
<span class="math notranslate nohighlight">\(t_{k+1}\)</span> as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\hat{f}(\pmb{x};t_{k+1}) = \sum_{i = 1}^I \ell_i f(\pmb{x}; t_{k - i + 1})\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(I \in \mathbb{N}\)</span> denotes the order, that is, the number of
past functions to use, and with coefficients:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\ell_i = \prod_{1 \leq j \leq I, \ j \neq i} \frac{j}{j - i}.\]</div>
</div></blockquote>
<dl class="footnote brackets">
<dt class="label" id="id47"><span class="brackets">1</span></dt>
<dd><p>N. Bastianello, A. Simonetto, and R. Carli, “Primal and Dual
Prediction-Correction Methods for Time-Varying Convex Optimization,”
arXiv:2004.11709 [cs, math], Oct. 2020. Available:
http://arxiv.org/abs/2004.11709.</p>
</dd>
</dl>
<dl class="py method">
<dt id="tvopt.prediction.ExtrapolationPrediction.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.ExtrapolationPrediction.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the current prediction.</p>
<p>This method updates the current prediction by building a new predicted
cost using the samples observed up to time <cite>t</cite>. By default this method
samples the dynamic cost, and should be overwritten when implementing
a custom prediction strategy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> (<em>float</em>) – The time of the last sampled cost.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.prediction.Prediction">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.prediction.</code><code class="sig-name descname">Prediction</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cost</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.Prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.costs.Cost</span></code></a></p>
<p>Prediction of a dynamic cost.</p>
<p>This class creates a cost object that predicts a given dynamic function.
The object stores a dynamic cost and a predicted cost, which can be
modified using new information through the method <cite>update</cite>.</p>
<dl class="py method">
<dt id="tvopt.prediction.Prediction.function">
<code class="sig-name descname">function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.Prediction.function" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the cost should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the cost should be evaluated. Not required if the
cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.prediction.Prediction.gradient">
<code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.Prediction.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s gradient or sub-gradient. <em>Implement if
needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the (sub-)gradient should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the (sub-)gradient should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.prediction.Prediction.hessian">
<code class="sig-name descname">hessian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.Prediction.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s Hessian. <em>Implement if needed</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the Hessian should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the Hessian should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.prediction.Prediction.proximal">
<code class="sig-name descname">proximal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.Prediction.proximal" title="Permalink to this definition">¶</a></dt>
<dd><p>An evaluation of the cost’s proximal.</p>
<p>If this method is not overwritten, the default behavior is to
recursively compute the proximal via a gradient or Newton backtracking
algorithm. See <cite>compute_proximal</cite> for the function that is used
for this purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The x where the proximal should be evaluated.</p></li>
<li><p><strong>*args</strong> – The time at which the proximal should be evaluated. Not
required if the cost is static.</p></li>
<li><p><strong>penalty</strong> (<em>float</em><em>, </em><em>optional</em>) – The penalty parameter :math:<a href="#id48"><span class="problematic" id="id49">`</span></a></p></li>
<li><p><strong>for the proximal evaluation.</strong> (<em>ho`</em>) – Defaults to <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p><strong>**kwargs</strong> – Any other required argument.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.prediction.Prediction.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.Prediction.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the current prediction.</p>
<p>This method updates the current prediction by building a new predicted
cost using the samples observed up to time <cite>t</cite>. By default this method
samples the dynamic cost, and should be overwritten when implementing
a custom prediction strategy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> (<em>float</em>) – The time of the last sampled cost.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.prediction.TaylorPrediction">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.prediction.</code><code class="sig-name descname">TaylorPrediction</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cost</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.TaylorPrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.prediction.Prediction" title="tvopt.prediction.Prediction"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.prediction.Prediction</span></code></a></p>
<p>Taylor expansion-based prediction.</p>
<p>This prediction strategy, proposed in [1]__ and see also [2]__, predicts
the cost at time <span class="math notranslate nohighlight">\(t_{k+1}\)</span> using its Taylor expansion around
<span class="math notranslate nohighlight">\(t_k\)</span> and a given <span class="math notranslate nohighlight">\(\pmb{x}_k\)</span>:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}\begin{split} \hat{f}(\pmb{x}; t_{k+1}) &amp;= f(\pmb{x}_k;t_k) + \langle \nabla_x f(\pmb{x}_k;t_k), \pmb{x} - \pmb{x}_k \rangle
+ T_s \nabla_t f(\pmb{x}_k;t_k) + (T_s^2 / 2) \nabla_{tt} f(\pmb{x}_k;t_k) +\\
&amp;+ T_s \langle \nabla_{tx} f(\pmb{x}_k;t_k), \pmb{x} - \pmb{x}_k \rangle
+ \frac{1}{2} (\pmb{x} - \pmb{x}_k)^\top \nabla_{xx} f(\pmb{x}_k;t_k) (\pmb{x} - \pmb{x}_k)
\end{split}\end{split}\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(T_s\)</span> is the sampling time.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id50"><span class="brackets">1</span></dt>
<dd><p>A. Simonetto, A. Mokhtari, A. Koppel, G. Leus, and A. Ribeiro,
“A Class of Prediction-Correction Methods for Time-Varying
Convex Optimization,” IEEE Transactions on Signal Processing,
vol. 64, no. 17, pp. 4576–4591, Sep. 2016.</p>
</dd>
<dt class="label" id="id51"><span class="brackets">2</span></dt>
<dd><p>N. Bastianello, A. Simonetto, and R. Carli, “Primal and Dual
Prediction-Correction Methods for Time-Varying Convex Optimization,”
arXiv:2004.11709 [cs, math], Oct. 2020. Available:
http://arxiv.org/abs/2004.11709.</p>
</dd>
</dl>
<dl class="py method">
<dt id="tvopt.prediction.TaylorPrediction.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">gradient_only</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.prediction.TaylorPrediction.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the current prediction.</p>
<p>This method updates the current prediction by building a new predicted
cost using the samples observed up to time <cite>t</cite>. By default this method
samples the dynamic cost, and should be overwritten when implementing
a custom prediction strategy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> (<em>float</em>) – The time of the last sampled cost.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-tvopt.sets">
<span id="tvopt-sets-module"></span><h2>tvopt.sets module<a class="headerlink" href="#module-tvopt.sets" title="Permalink to this headline">¶</a></h2>
<p>Set template and examples.</p>
<dl class="py class">
<dt id="tvopt.sets.AffineSet">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">AffineSet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.AffineSet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Affine set.</p>
<p>This class implements:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ x \in \mathbb{R}^n \ | \ A x = b \}\]</div>
</div></blockquote>
<p>for given matrix <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}\)</span> and vector
<span class="math notranslate nohighlight">\(b \in \mathbb{R}^{m}\)</span>.</p>
<dl class="py method">
<dt id="tvopt.sets.AffineSet.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.AffineSet.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.AffineSet.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.AffineSet.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.Ball">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">Ball</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">center</span></em>, <em class="sig-param"><span class="n">radius</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Ball" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Ball set.</p>
<p>This class implements:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ x \in \mathbb{R}^n \ | \ \| x - c \| \leq r \}\]</div>
</div></blockquote>
<p>for a center <span class="math notranslate nohighlight">\(c\)</span> and radius <span class="math notranslate nohighlight">\(r &gt; 0\)</span>.</p>
<dl class="py method">
<dt id="tvopt.sets.Ball.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Ball.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Ball.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Ball.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.Ball_l1">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">Ball_l1</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">center</span></em>, <em class="sig-param"><span class="n">radius</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Ball_l1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p><span class="math notranslate nohighlight">\(\ell_1\)</span>-ball set.</p>
<p>This class implements:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ x \in \mathbb{R}^n \ | \ \| x - c \|_1 \leq r \}\]</div>
</div></blockquote>
<p>for a center <span class="math notranslate nohighlight">\(c\)</span> and radius <span class="math notranslate nohighlight">\(r &gt; 0\)</span>.</p>
<dl class="py method">
<dt id="tvopt.sets.Ball_l1.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Ball_l1.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Ball_l1.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-05</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Ball_l1.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.Box">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">Box</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">l</span></em>, <em class="sig-param"><span class="n">u</span></em>, <em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Box" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Box set.</p>
<p>This class implements:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ x \in \mathbb{R}^n \ | \ l \leq x \leq u \}\]</div>
</div></blockquote>
<p>with bounds <span class="math notranslate nohighlight">\(l, u\)</span> either scalar (applied element-wise) or vectors.</p>
<dl class="py method">
<dt id="tvopt.sets.Box.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Box.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Box.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Box.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.Halfspace">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">Halfspace</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Halfspace" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Halfspace.</p>
<p>This class implements:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ x \in \mathbb{R}^n \ | \ \langle a, x \rangle = b \}\]</div>
</div></blockquote>
<p>for given vetor <span class="math notranslate nohighlight">\(a \in \mathbb{R}^{n}\)</span> and scalar
<span class="math notranslate nohighlight">\(b \in \mathbb{R}\)</span>.</p>
<dl class="py method">
<dt id="tvopt.sets.Halfspace.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Halfspace.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Halfspace.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Halfspace.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.IntersectionSet">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">IntersectionSet</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">sets</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.IntersectionSet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Intersection of sets.</p>
<p>Given the sets <span class="math notranslate nohighlight">\(\mathbb{S}_i\)</span>, <span class="math notranslate nohighlight">\(i = 1, \ldots, N\)</span> this class
implements</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\bigcap_{i = 1}^N \mathbb{S}_i.\]</div>
</div></blockquote>
<dl class="py method">
<dt id="tvopt.sets.IntersectionSet.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.IntersectionSet.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.IntersectionSet.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.IntersectionSet.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Projection onto the intersection.</p>
<p>This method returns an approximate projection onto the intersection of
sets, computed using the method of alteranting projections.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#tvopt.sets.alternating_projections" title="tvopt.sets.alternating_projections"><code class="xref py py-meth docutils literal notranslate"><span class="pre">alternating_projections()</span></code></a></dt><dd><p>method of alternating projection</p>
</dd>
</dl>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.NonnegativeOrthant">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">NonnegativeOrthant</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.NonnegativeOrthant" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Non-negative orthant.</p>
<p>This class implements:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ x \in \mathbb{R}^n \ | \ x \geq 0 \}\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(x \geq 0\)</span> if <span class="math notranslate nohighlight">\(x\)</span> is component-wise non-negative.</p>
<dl class="py method">
<dt id="tvopt.sets.NonnegativeOrthant.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.NonnegativeOrthant.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.NonnegativeOrthant.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.NonnegativeOrthant.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.R">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">R</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">dims</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.R" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>The underlying space.</p>
<p>This class implements the underlying space
<span class="math notranslate nohighlight">\(\mathbb{R}^{n_1 \times n_2 \times \ldots}\)</span>.</p>
<dl class="py method">
<dt id="tvopt.sets.R.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.R.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.R.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.R.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.ScaledSet">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">ScaledSet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">s</span></em>, <em class="sig-param"><span class="n">c</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.ScaledSet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Scaled set.</p>
<p>Given a set <span class="math notranslate nohighlight">\(\mathbb{S}\)</span> and a scalar <span class="math notranslate nohighlight">\(c\)</span>, this class defines</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ c x \ \forall x \in \mathbb{S} \}.\]</div>
</div></blockquote>
<dl class="py method">
<dt id="tvopt.sets.ScaledSet.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.ScaledSet.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.ScaledSet.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.ScaledSet.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.Set">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">Set</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">dims</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Set" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Template for a set.</p>
<p>This class defines a non-empty, closed, convex set in
<span class="math notranslate nohighlight">\(\mathbb{R}^{n_1 \times n_2 \times \ldots}\)</span>. These objects are
defined by a <cite>contains</cite> method (to check if an input belongs to the set)
and a <cite>projection</cite> method.</p>
<p>Sets can be translated and scaled (via the respective methods). The
<cite>contains</cite> method can also be accessed via the built-in <cite>in</cite> operator.
Using <cite>+</cite> it is possible to intersect sets.</p>
<dl class="py attribute">
<dt id="tvopt.sets.Set.shape">
<code class="sig-name descname">shape</code><a class="headerlink" href="#tvopt.sets.Set.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The dimensions of the underlying space.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.sets.Set.ndim">
<code class="sig-name descname">ndim</code><a class="headerlink" href="#tvopt.sets.Set.ndim" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of dimensions of the underlying space.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tvopt.sets.Set.size">
<code class="sig-name descname">size</code><a class="headerlink" href="#tvopt.sets.Set.size" title="Permalink to this definition">¶</a></dt>
<dd><p>The product of each dimension’s size.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Set.check_input">
<code class="sig-name descname">check_input</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Set.check_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Check dimension of input.</p>
<p>This method verifies if the argument <cite>x</cite> belong to the space underlying
the set, possibly reshaping it. If it is not compatible or cannot be
reshaped (using numpy’s broadcasting rules), and exception is raised.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – The input to be checked.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The (possibly reshaped) input if it is compatible with the space.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Set.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Set.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Set.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Set.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Set.scale">
<code class="sig-name descname">scale</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">c</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Set.scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.Set.translate">
<code class="sig-name descname">translate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.Set.translate" title="Permalink to this definition">¶</a></dt>
<dd><p>Translate the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.T">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">T</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t_s</span></em>, <em class="sig-param"><span class="n">t_min</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">t_max</span><span class="o">=</span><span class="default_value">inf</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.T" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Set of sampling times.</p>
<p>This class implements the set of sampling times:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ t_k \geq 0, \ k \in \mathbb{N} \}\]</div>
</div></blockquote>
<p>with <span class="math notranslate nohighlight">\(t_{k+1} - t_k = T_\mathrm{s}\)</span> for a sampling time
<span class="math notranslate nohighlight">\(T_\mathrm{s}\)</span>.</p>
<dl class="py method">
<dt id="tvopt.sets.T.check_input">
<code class="sig-name descname">check_input</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.T.check_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Check dimension of input.</p>
<p>This method verifies if the argument <cite>x</cite> belong to the space underlying
the set, possibly reshaping it. If it is not compatible or cannot be
reshaped (using numpy’s broadcasting rules), and exception is raised.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – The input to be checked.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The (possibly reshaped) input if it is compatible with the space.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.T.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.T.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.T.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.T.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.T.scale">
<code class="sig-name descname">scale</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">c</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.T.scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.T.translate">
<code class="sig-name descname">translate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.T.translate" title="Permalink to this definition">¶</a></dt>
<dd><p>Translate the set.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="tvopt.sets.TranslatedSet">
<em class="property">class </em><code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">TranslatedSet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">s</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.TranslatedSet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#tvopt.sets.Set" title="tvopt.sets.Set"><code class="xref py py-class docutils literal notranslate"><span class="pre">tvopt.sets.Set</span></code></a></p>
<p>Translated set.</p>
<p>Given a set <span class="math notranslate nohighlight">\(\mathbb{S}\)</span> and a vector <span class="math notranslate nohighlight">\(t\)</span>, this class defines</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ x + t \ \forall x \in \mathbb{S} \}.\]</div>
</div></blockquote>
<dl class="py method">
<dt id="tvopt.sets.TranslatedSet.contains">
<code class="sig-name descname">contains</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.TranslatedSet.contains" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input belongs to the set.</p>
</dd></dl>

<dl class="py method">
<dt id="tvopt.sets.TranslatedSet.projection">
<code class="sig-name descname">projection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.TranslatedSet.projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the input onto the set.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="tvopt.sets.alternating_projections">
<code class="sig-prename descclassname">tvopt.sets.</code><code class="sig-name descname">alternating_projections</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sets</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-10</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">10</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.sets.alternating_projections" title="Permalink to this definition">¶</a></dt>
<dd><p>Method of alternating projections.</p>
<p>This function returns a point in the intersection of the given convex
sets, computed using the method of alternating projections (MAP) [1]__.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – The starting point.</p></li>
<li><p><strong>sets</strong> (<em>list</em>) – The list of sets.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – The stopping condition. If the difference between consecutive iterates
is smaller than or equal to <cite>tol</cite>, then the function returns.
Defaults to <span class="math notranslate nohighlight">\(10^{-10}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The maximum number of iterations of the projection algorithm. Defaults
to <span class="math notranslate nohighlight">\(1000\)</span>. This stopping condition is enacted if the algorithm
does not reach <cite>tol</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – A point in the intersection.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id52"><span class="brackets">1</span></dt>
<dd><p>H. Bauschke and V. Koch, “Projection Methods: Swiss Army Knives for
Solving Feasibility and Best Approximation Problems with
Halfspaces,” in Contemporary Mathematics, vol. 636, S. Reich and
A. Zaslavski, Eds. Providence, Rhode Island:
American Mathematical Society, 2015, pp. 1–40.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-tvopt.solvers">
<span id="tvopt-solvers-module"></span><h2>tvopt.solvers module<a class="headerlink" href="#module-tvopt.solvers" title="Permalink to this headline">¶</a></h2>
<p>Solvers.</p>
<dl class="py function">
<dt id="tvopt.solvers.admm">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">admm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">penalty</span></em>, <em class="sig-param"><span class="n">rel</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">w_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.admm" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternating direction method of multipliers (ADMM).</p>
<p>This function implements the ADMM to solve the constrained problem</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
&amp;\min_{\pmb{x},\pmb{y}} \left\{ f(\pmb{x}) + g(\pmb{y}) \right\} \\
&amp;\text{s.t.} \ \pmb{A} \pmb{x} +  \pmb{B} \pmb{y} = \pmb{c}.
\end{align}\end{split}\]</div>
</div></blockquote>
<p>The algorithm is characterized by the updates:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{x}^\ell &amp;= \operatorname{arg\,min}_{\pmb{x}} \left\{ f(\pmb{x})
- \langle \pmb{z}^\ell, \pmb{A} \pmb{x} \rangle + \frac{\rho}{2} \| \pmb{A} \pmb{x} - \pmb{c} \|^2 \right\} \\
\pmb{w}^\ell &amp;= \pmb{z}^\ell - \rho (\pmb{A} \pmb{x}^\ell - \pmb{c}) \\
\pmb{y}^\ell &amp;= \operatorname{arg\,min}_{\pmb{y}} \left\{ g(\pmb{y})
- \langle 2 \pmb{w}^\ell - \pmb{z}^\ell, \pmb{B} \pmb{y} \rangle + \frac{\rho}{2} \| \pmb{B} \pmb{y} \|^2 \right\} \\
\pmb{u}^\ell &amp;= 2 \pmb{w}^\ell - \pmb{z}^\ell - \rho \pmb{B} \pmb{y}^\ell \\
\pmb{z}^{\ell+1} &amp;= \pmb{z}^\ell + 2 \alpha (\pmb{u}^\ell - \pmb{w}^\ell)
\end{align}\end{split}\]</div>
</div></blockquote>
<p>for a given penalty <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span> and <span class="math notranslate nohighlight">\(\alpha \in (0,1]\)</span> is the
relaxation constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the costs <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span>, and the constraints
<span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(c\)</span>.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The algorithm’s penalty.</p></li>
<li><p><strong>rel</strong> (<em>float</em><em>, </em><em>optional</em>) – The relaxation constant.</p></li>
<li><p><strong>w_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The dual initial condition. This can be either an ndarray of suitable
size, or a scalar. If it is a scalar then the same initial value is
used for all components of <span class="math notranslate nohighlight">\(\pmb{w}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
dual stopping condition
<span class="math notranslate nohighlight">\(\| \pmb{w}^{\ell+1} - \pmb{w}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The approximate primal solution <span class="math notranslate nohighlight">\(\pmb{x}\)</span> after <cite>num_iter</cite> iterations.</p></li>
<li><p><strong>y</strong> (<em>ndarray</em>) – The approximate primal solution <span class="math notranslate nohighlight">\(\pmb{y}\)</span> after <cite>num_iter</cite> iterations.</p></li>
<li><p><strong>w</strong> (<em>ndarray</em>) – The approximate dual solution after <cite>num_iter</cite> iterations.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.backtracking_gradient">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">backtracking_gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">r</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">c</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.backtracking_gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradient method with backtracking line search.</p>
<p>This function implements the gradient method</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\pmb{x}^{\ell+1} = \pmb{x}^\ell - \alpha^\ell \nabla f(\pmb{x}^\ell)\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\alpha^\ell\)</span> is chosen via a backtracking line search. In
particular, at each iteration we start with <span class="math notranslate nohighlight">\(\alpha^\ell = 1\)</span> and,
while</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(\pmb{x}^\ell - \alpha^\ell \nabla f(\pmb{x}^\ell)) &gt;
f(\pmb{x}^\ell) - c \alpha^\ell \| \nabla f(\pmb{x}^\ell) \|^2\]</div>
</div></blockquote>
<p>we set <span class="math notranslate nohighlight">\(\alpha^\ell = r \alpha^\ell\)</span> until a suitable step is found.</p>
<p>Note that the backtracking line search does not stop until a suitable
step-size  si found; this means that large <cite>r</cite> parameters may result in
big computation times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the cost <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
<li><p><strong>r</strong> (<em>float</em><em>, </em><em>optional</em>) – The value by which a candidate step-size is multiplied if it does not
satisfy the descent condition. <cite>r</cite> should be in <span class="math notranslate nohighlight">\((0,1)\)</span>.</p></li>
<li><p><strong>c</strong> (<em>float</em><em>, </em><em>optional</em>) – The parameter defining the descent condition that a candidate step
must satisfy.</p></li>
<li><p><strong>x_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The initial condition. This can be either an ndarray of suitable size,
or a scalar. If it is a scalar then the same initial value is used for
all components of <span class="math notranslate nohighlight">\(\pmb{x}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
stopping condition <span class="math notranslate nohighlight">\(\| \pmb{x}^{\ell+1} - \pmb{x}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The approximate solution after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.dual_ascent">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">dual_ascent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">penalty</span></em>, <em class="sig-param"><span class="n">w_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.dual_ascent" title="Permalink to this definition">¶</a></dt>
<dd><p>Dual ascent.</p>
<p>This function implements the dual ascent to solve the constrained problem</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\min_{\pmb{x}} f(\pmb{x}) \ \text{s.t.} \ \pmb{A} \pmb{x} = \pmb{c}.\]</div>
</div></blockquote>
<p>The algorithm is characterized by the updates:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{x}^\ell &amp;= \operatorname{arg\,min}_{\pmb{x}} \left\{ f(\pmb{x}) - \langle \pmb{w}^\ell, \pmb{A} \pmb{x} \rangle \right\} \\
\pmb{w}^{\ell+1} &amp;= \pmb{w}^\ell - \rho (\pmb{A} \pmb{x}^\ell - \pmb{c})
\end{align}\end{split}\]</div>
</div></blockquote>
<p>for a given penalty <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the cost <span class="math notranslate nohighlight">\(f\)</span>, and the constraints <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(c\)</span>.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The algorithm’s penalty.</p></li>
<li><p><strong>w_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The dual initial condition. This can be either an ndarray of suitable
size, or a scalar. If it is a scalar then the same initial value is
used for all components of <span class="math notranslate nohighlight">\(\pmb{w}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
dual stopping condition
<span class="math notranslate nohighlight">\(\| \pmb{w}^{\ell+1} - \pmb{w}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The approximate primal solution after <cite>num_iter</cite> iterations.</p></li>
<li><p><strong>w</strong> (<em>ndarray</em>) – The approximate dual solution after <cite>num_iter</cite> iterations.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.dual_fbs">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">dual_fbs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">penalty</span></em>, <em class="sig-param"><span class="n">rel</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">w_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.dual_fbs" title="Permalink to this definition">¶</a></dt>
<dd><p>Dual forward-backward splitting.</p>
<p>This function implements the dual FBS to solve the constrained problem</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
&amp;\min_{\pmb{x},\pmb{y}} \left\{ f(\pmb{x}) + g(\pmb{y}) \right\} \\
&amp;\text{s.t.} \ \pmb{A} \pmb{x} +  \pmb{B} \pmb{y} = \pmb{c}.
\end{align}\end{split}\]</div>
</div></blockquote>
<p>The algorithm is characterized by the updates:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{x}^\ell &amp;= \operatorname{arg\,min}_{\pmb{x}} \left\{ f(\pmb{x}) - \langle \pmb{w}, \pmb{A} \pmb{x} \rangle \right\} \\
\pmb{u}^\ell &amp;= \pmb{w}^\ell - \rho (\pmb{A} \pmb{x}^\ell - \pmb{c}) \\
\pmb{y}^\ell &amp;= \operatorname{arg\,min}_{\pmb{y}} \left\{ g(\pmb{y})
- \langle \pmb{u}^\ell, \pmb{B} \pmb{y} \rangle + \frac{\rho}{2} \| \pmb{B} \pmb{y} \|^2 \right\} \\
\pmb{w}^{\ell+1} &amp;= (1-\alpha) \pmb{w}^\ell + \alpha (\pmb{u}^\ell - \rho \pmb{B} \pmb{y}^\ell)
\end{align}\end{split}\]</div>
</div></blockquote>
<p>for a given penalty <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span> and <span class="math notranslate nohighlight">\(\alpha \in (0,1]\)</span> is the
relaxation constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the costs <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span>, and the constraints
<span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(c\)</span>.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The algorithm’s penalty.</p></li>
<li><p><strong>rel</strong> (<em>float</em><em>, </em><em>optional</em>) – The relaxation constant.</p></li>
<li><p><strong>w_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The dual initial condition. This can be either an ndarray of suitable
size, or a scalar. If it is a scalar then the same initial value is
used for all components of <span class="math notranslate nohighlight">\(\pmb{w}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
dual stopping condition
<span class="math notranslate nohighlight">\(\| \pmb{w}^{\ell+1} - \pmb{w}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The approximate primal solution <span class="math notranslate nohighlight">\(\pmb{x}\)</span> after <cite>num_iter</cite> iterations.</p></li>
<li><p><strong>y</strong> (<em>ndarray</em>) – The approximate primal solution <span class="math notranslate nohighlight">\(\pmb{y}\)</span> after <cite>num_iter</cite> iterations.</p></li>
<li><p><strong>w</strong> (<em>ndarray</em>) – The approximate dual solution after <cite>num_iter</cite> iterations.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.fbs">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">fbs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">rel</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.fbs" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward-backward splitting (FBS).</p>
<p>This function implements the forward-backward splitting (a.k.a. proximal
gradient method) to solve the composite problem</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\min_{\pmb{x}} \{ f(\pmb{x}) + g(\pmb{x}) \}.\]</div>
</div></blockquote>
<p>The algorithm is characterized by the update:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\pmb{x}^{\ell+1} = (1-\alpha) \pmb{x}^\ell +
\alpha \operatorname{prox}_{\rho g}(\pmb{x}^\ell - \rho \nabla f(\pmb{x}^\ell))\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span> is the step-size and <span class="math notranslate nohighlight">\(\alpha \in (0,1]\)</span> is the
relaxation constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the costs <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span>.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – The algorithm’s step-size.</p></li>
<li><p><strong>rel</strong> (<em>float</em><em>, </em><em>optional</em>) – The relaxation constant.</p></li>
<li><p><strong>x_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The initial condition. This can be either an ndarray of suitable size,
or a scalar. If it is a scalar then the same initial value is used for
all components of <span class="math notranslate nohighlight">\(\pmb{x}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
stopping condition <span class="math notranslate nohighlight">\(\| \pmb{x}^{\ell+1} - \pmb{x}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The approximate solution after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.gradient">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">gradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradient method.</p>
<p>This function implements the gradient method</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\pmb{x}^{\ell+1} = \pmb{x}^\ell - \alpha \nabla f(\pmb{x}^\ell)\]</div>
</div></blockquote>
<p>for a given step-size <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the cost <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – The algorithm’s step-size.</p></li>
<li><p><strong>x_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The initial condition. This can be either an ndarray of suitable size,
or a scalar. If it is a scalar then the same initial value is used for
all components of <span class="math notranslate nohighlight">\(\pmb{x}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
stopping condition <span class="math notranslate nohighlight">\(\| \pmb{x}^{\ell+1} - \pmb{x}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The approximate solution after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.mm">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">mm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">penalty</span></em>, <em class="sig-param"><span class="n">w_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.mm" title="Permalink to this definition">¶</a></dt>
<dd><p>Method of multipliers (MM).</p>
<p>This function implements the method of multipliers to solve the constrained
problem</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\min_{\pmb{x}} f(\pmb{x}) \ \text{s.t.} \ \pmb{A} \pmb{x} = \pmb{c}.\]</div>
</div></blockquote>
<p>The algorithm is characterized by the updates:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\pmb{x}^\ell &amp;= \operatorname{arg\,min}_{\pmb{x}} \left\{ f(\pmb{x})
- \langle \pmb{w}^\ell, \pmb{A} \pmb{x} \rangle + \frac{\rho}{2} \| \pmb{A} \pmb{x} - \pmb{c} \|^2 \right\} \\
\pmb{w}^{\ell+1} &amp;= \pmb{w}^\ell - \rho (\pmb{A} \pmb{x}^\ell - \pmb{c})
\end{align}\end{split}\]</div>
</div></blockquote>
<p>for a given penalty <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the cost <span class="math notranslate nohighlight">\(f\)</span>, and the constraints <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(c\)</span>.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The algorithm’s penalty.</p></li>
<li><p><strong>w_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The dual initial condition. This can be either an ndarray of suitable
size, or a scalar. If it is a scalar then the same initial value is
used for all components of <span class="math notranslate nohighlight">\(\pmb{w}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
dual stopping condition
<span class="math notranslate nohighlight">\(\| \pmb{w}^{\ell+1} - \pmb{w}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The approximate primal solution after <cite>num_iter</cite> iterations.</p></li>
<li><p><strong>w</strong> (<em>ndarray</em>) – The approximate dual solution after <cite>num_iter</cite> iterations.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.newton">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">newton</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">r</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">c</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.newton" title="Permalink to this definition">¶</a></dt>
<dd><p>Newton method with backtracking line search.</p>
<p>This function implements the Newton method</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\pmb{x}^{\ell+1} = \pmb{x}^\ell - \alpha^\ell \nabla^2 f(\pmb{x}^\ell)^{-1} \nabla f(\pmb{x}^\ell)\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\alpha^\ell\)</span> is chosen via a backtracking line search. In
particular, at each iteration we start with <span class="math notranslate nohighlight">\(\alpha^\ell = 1\)</span> and,
while</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[f(\pmb{x}^\ell - \alpha^\ell \nabla^2 f(\pmb{x}^\ell)^{-1} \nabla f(\pmb{x}^\ell)) &gt;
f(\pmb{x}^\ell) - c \alpha^\ell \| \nabla f(\pmb{x}^\ell) \|^2\]</div>
</div></blockquote>
<p>we set <span class="math notranslate nohighlight">\(\alpha^\ell = r \alpha^\ell\)</span> until a suitable step is found.</p>
<p>Note that the backtracking line search does not stop until a suitable
step-size  si found; this means that large <cite>r</cite> parameters may result in
big computation times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the cost <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
<li><p><strong>r</strong> (<em>float</em><em>, </em><em>optional</em>) – The value by which a candidate step-size is multiplied if it does not
satisfy the descent condition. <cite>r</cite> should be in <span class="math notranslate nohighlight">\((0,1)\)</span>.</p></li>
<li><p><strong>c</strong> (<em>float</em><em>, </em><em>optional</em>) – The parameter defining the descent condition that a candidate step
must satisfy.</p></li>
<li><p><strong>x_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The initial condition. This can be either an ndarray of suitable size,
or a scalar. If it is a scalar then the same initial value is used for
all components of <span class="math notranslate nohighlight">\(\pmb{x}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
stopping condition <span class="math notranslate nohighlight">\(\| \pmb{x}^{\ell+1} - \pmb{x}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The approximate solution after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.ppa">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">ppa</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">penalty</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.ppa" title="Permalink to this definition">¶</a></dt>
<dd><p>Proximal point algorithm (PPA).</p>
<p>This function implements the proximal point algorithm</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\pmb{x}^{\ell+1} = \operatorname{prox}_{\rho f}(\pmb{x}^\ell)\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span> is the penalty parameter and we recall that</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\operatorname{prox}_{\rho f}(\pmb{x}) =
\operatorname{arg\,min}_{\pmb{y}} \left\{ f(\pmb{y}) + \frac{1}{2\rho} \| \pmb{y} - \pmb{x} \|^2 \right\}.\]</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the cost <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The penalty parameter for the proximal evaluation.</p></li>
<li><p><strong>x_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The initial condition. This can be either an ndarray of suitable size,
or a scalar. If it is a scalar then the same initial value is used for
all components of <span class="math notranslate nohighlight">\(\pmb{x}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
stopping condition <span class="math notranslate nohighlight">\(\| \pmb{x}^{\ell+1} - \pmb{x}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The approximate solution after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.prs">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">prs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">penalty</span></em>, <em class="sig-param"><span class="n">rel</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.prs" title="Permalink to this definition">¶</a></dt>
<dd><p>Peaceman-Rachford splitting (PRS).</p>
<p>This function implements the Peaceman-Rachford splitting to solve the
composite problem</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\min_{\pmb{x}} \{ f(\pmb{x}) + g(\pmb{x}) \}.\]</div>
</div></blockquote>
<p>The algorithm is characterized by the updates:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}\begin{align} \pmb{x}^\ell &amp;= \operatorname{prox}_{\rho f}(\pmb{z}^\ell) \\
\pmb{y}^\ell &amp;= \operatorname{prox}_{\rho g}(2 \pmb{x}^\ell - \pmb{z}^\ell) \\
\pmb{z}^{\ell+1} &amp;= \pmb{z}^\ell + 2 \alpha (\pmb{y}^\ell - \pmb{x}^\ell)
\end{align}\end{split}\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span> is the penalty and <span class="math notranslate nohighlight">\(\alpha \in (0,1]\)</span> is the
relaxation constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the costs <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span>.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The algorithm’s penalty parameter.</p></li>
<li><p><strong>rel</strong> (<em>float</em><em>, </em><em>optional</em>) – The relaxation constant.</p></li>
<li><p><strong>x_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The initial condition. This can be either an ndarray of suitable size,
or a scalar. If it is a scalar then the same initial value is used for
all components of <span class="math notranslate nohighlight">\(\pmb{x}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
stopping condition <span class="math notranslate nohighlight">\(\| \pmb{x}^{\ell+1} - \pmb{x}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The approximate solution after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.stop">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">stop</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">x_old</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.stop" title="Permalink to this definition">¶</a></dt>
<dd><p>Stopping condition.</p>
<p>This function checks the stopping condition</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\| \pmb{x}^{\ell+1} - \pmb{x}^\ell \| \leq t\]</div>
</div></blockquote>
<p>if <cite>t</cite> is specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The current iterate.</p></li>
<li><p><strong>x_old</strong> (<em>ndarray</em>) – The previous iterate.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – The tolerance in the stopping condition.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if <cite>tol</cite> is given and the stopping condition is verified, False
otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.solvers.subgradient">
<code class="sig-prename descclassname">tvopt.solvers.</code><code class="sig-name descname">subgradient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">problem</span></em>, <em class="sig-param"><span class="n">x_0</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">num_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.solvers.subgradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Sub-gradient method.</p>
<p>This function implements the sub-gradient method</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\pmb{x}^{\ell+1} = \pmb{x}^\ell - \alpha^\ell \tilde{\nabla} f(\pmb{x}^\ell)\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\tilde{\nabla} f(\pmb{x}^\ell) \in \partial f(\pmb{x}^\ell)\)</span>
is a sub-differential and <span class="math notranslate nohighlight">\(\alpha^\ell = 1 / (\ell + 1)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>problem</strong> (<em>dict</em>) – Problem dictionary defining the cost <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
<li><p><strong>x_0</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The initial condition. This can be either an ndarray of suitable size,
or a scalar. If it is a scalar then the same initial value is used for
all components of <span class="math notranslate nohighlight">\(\pmb{x}\)</span>.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of iterations to be performed.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – If given, this argument specifies the tolerance <span class="math notranslate nohighlight">\(t\)</span> in the
stopping condition <span class="math notranslate nohighlight">\(\| \pmb{x}^{\ell+1} - \pmb{x}^\ell \| \leq t\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The approximate solution after <cite>num_iter</cite> iterations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-tvopt.utils">
<span id="tvopt-utils-module"></span><h2>tvopt.utils module<a class="headerlink" href="#module-tvopt.utils" title="Permalink to this headline">¶</a></h2>
<p>Utility tools.</p>
<dl class="py function">
<dt id="tvopt.utils.bisection_method">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">bisection_method</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f</span></em>, <em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-05</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.bisection_method" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimize using the bisection method.</p>
<p>This function minimizes a function <cite>f</cite> using the bisection method, stopping
when <span class="math notranslate nohighlight">\(a - b \leq t\)</span> for some threshold <span class="math notranslate nohighlight">\(t\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> – The scalar function to be minimized.</p></li>
<li><p><strong>a</strong> (<em>float</em>) – The lower bound of the initial interval.</p></li>
<li><p><strong>b</strong> (<em>float</em>) – the upper bound of the initial interval.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – The stopping condition, defaults to 1e-5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The approximate minimizer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.dist">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">dist</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">s</span></em>, <em class="sig-param"><span class="n">r</span></em>, <em class="sig-param"><span class="n">ord</span><span class="o">=</span><span class="default_value">2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Distance of a signal from a reference.</p>
<p>This function computes the distance of a signal <cite>s</cite> from a reference <cite>r</cite>.
The reference can be either constant or a signal itself.
Different norm orders can be used, that can be specified using the
<cite>numpy.linalg.norm</cite> argument <cite>ord</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<em>array_like</em>) – The signal, with the last dimension indexing time.</p></li>
<li><p><strong>r</strong> (<em>array_like</em>) – The reference, either a single array or a signal with the last
dimension indexing time.</p></li>
<li><p><strong>ord</strong> (<em>optional</em>) – Norm order, see <cite>numpy.linalg.norm</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – For incompatible dimensions of signal and reference.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>DESCRIPTION.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>TYPE</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.fpr">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">fpr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">s</span></em>, <em class="sig-param"><span class="n">ord</span><span class="o">=</span><span class="default_value">2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.fpr" title="Permalink to this definition">¶</a></dt>
<dd><p>Fixed point residual.</p>
<p>This function computes the fixed point residual of a signal <cite>s</cite>,
that is</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ \| s^\ell - s^{\ell-1} \|_i \}_{\ell \in \mathbb{N}}.\]</div>
</div></blockquote>
<p>Different norm orders can be used, that can be specified using the
<cite>numpy.linalg.norm</cite> argument <cite>ord</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<em>array_like</em>) – The signal, with the last dimension indexing time.</p></li>
<li><p><strong>ord</strong> (<em>optional</em>) – Norm order, see <cite>numpy.linalg.norm</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The fixed point residual.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.initialize_trajectory">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">initialize_trajectory</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_0</span></em>, <em class="sig-param"><span class="n">shape</span></em>, <em class="sig-param"><span class="n">num_iter</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.initialize_trajectory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="tvopt.utils.is_scalar">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">is_scalar</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">c</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.is_scalar" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if scalar.</p>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.is_square">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">is_square</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mat</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.is_square" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the matrix is 2-D and square.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mat</strong> (<em>ndarray</em>) – The given matrix.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if the matrix is 2-D and square, False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.is_stochastic">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">is_stochastic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mat</span></em>, <em class="sig-param"><span class="n">row</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">col</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.is_stochastic" title="Permalink to this definition">¶</a></dt>
<dd><p>Verify if a given matrix is row, column or doubly stochastic.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mat</strong> (<em>ndarray</em>) – The given matrix.</p></li>
<li><p><strong>row</strong> (<em>bool</em><em>, </em><em>optional</em>) – Check for row stochasticity, default True.</p></li>
<li><p><strong>col</strong> (<em>bool</em><em>, </em><em>optional</em>) – Check for column stochasticity, default True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if the matrix is stochastic (row, column or doubly, as specified
by the arguments).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If neither <cite>row</cite> nor <cite>col</cite> are True.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.norm">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">norm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the norm of the given vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – The vector array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The square norm.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#tvopt.utils.square_norm" title="tvopt.utils.square_norm"><code class="xref py py-func docutils literal notranslate"><span class="pre">square_norm()</span></code></a></dt><dd><p>Square norm</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The function reshapes <cite>x</cite> to a column vector, so it does not correctly
handle n-dimensional arrays. For n-dim arrays use <cite>numpy.linalg.norm</cite>.</p>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.normalize">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">normalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalize a vector to unit vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – The vector array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The normalized vector.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The function reshapes <cite>x</cite> to a column vector, so it does not correctly
handle n-dimensional arrays. For n-dim arrays use <cite>numpy.linalg.norm</cite>.</p>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.orthonormal_matrix">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">orthonormal_matrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dim</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.orthonormal_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a random orthonormal matrix.</p>
<p>This function generates uniformly distributed random orthonormal matrices
using Householder reflections (see Section 7 of <a class="reference external" href="https://arxiv.org/pdf/math-ph/0609050.pdf">this paper</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dim</strong> (<em>int</em>) – Size of the matrix.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>orth_mat</strong> – The random orthonormal matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – For invalid <cite>dim</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.positive_semidefinite_matrix">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">positive_semidefinite_matrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dim</span></em>, <em class="sig-param"><span class="n">eigs</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.positive_semidefinite_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a random positive semi-definite matrix.</p>
<p>The matrix is generated as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[M = O \mathrm{diag}\{ \lambda_i \} O^\top\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(O\)</span> is a random orthonormal matrix and <span class="math notranslate nohighlight">\(\lambda_i\)</span> are
random eigenvalues uniformly drawn between <cite>min_eig</cite> and <cite>max_eig</cite>. If
<cite>dim</cite> is larger than or equal to two, <cite>min_eig</cite> and <cite>max_eig</cite> are included
in the eigenvalues list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim</strong> (<em>int</em>) – Size of the matrix.</p></li>
<li><p><strong>eigs</strong> (<em>array-like</em><em>, </em><em>optional</em>) – The list of eigenvalues for the matrix; if None, the eigenvalues are
uniformly drawn from <span class="math notranslate nohighlight">\([10^{-2}, 10^2]\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The random positive semi-definite matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError.</strong> – </p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#tvopt.utils.orthonormal_matrix" title="tvopt.utils.orthonormal_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">orthonormal_matrix()</span></code></a></dt><dd><p>Orthonormal matrix generator.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.print_progress">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">print_progress</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">i</span></em>, <em class="sig-param"><span class="n">num_iter</span></em>, <em class="sig-param"><span class="n">bar_length</span><span class="o">=</span><span class="default_value">80</span></em>, <em class="sig-param"><span class="n">decimals</span><span class="o">=</span><span class="default_value">2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.print_progress" title="Permalink to this definition">¶</a></dt>
<dd><p>Print the progresso to command line.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>i</strong> (<em>int</em>) – Current iteration.</p></li>
<li><p><strong>num_iter</strong> (<em>int</em>) – Total number of iterations.</p></li>
<li><p><strong>bar_length</strong> (<em>int</em><em>, </em><em>optional</em>) – Length of progress bar.</p></li>
<li><p><strong>decimals</strong> (<em>int</em><em>, </em><em>optional</em>) – Decimal places of the progress percent.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Adapted from <a class="reference external" href="https://gist.github.com/aubricus/f91fb55dc6ba5557fbab06119420dd6a">here</a>.</p>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.regret">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">regret</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f</span></em>, <em class="sig-param"><span class="n">s</span></em>, <em class="sig-param"><span class="n">r</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.regret" title="Permalink to this definition">¶</a></dt>
<dd><p>Cost over time or regret.</p>
<p>This function computes the cost evaluated using <cite>f</cite> incurred by an
approximate minimizer <cite>s</cite></p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ \frac{1}{\ell} \sum_{j = 1}^\ell f(s^j) \}_{\ell \in \mathbb{N}}\]</div>
</div></blockquote>
<p>or, if a reference <cite>r</cite> is specified, then the function computes the regret</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\{ \frac{1}{\ell} \sum_{j = 1}^\ell f(s^j) - f(r^j) \}_{\ell \in \mathbb{N}}\]</div>
</div></blockquote>
<p>where <cite>r</cite> is either a constant array or a signal.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> (<a class="reference internal" href="#tvopt.costs.Cost" title="tvopt.costs.Cost"><em>costs.Cost</em></a>) – The cost to evaluate in the signal.</p></li>
<li><p><strong>s</strong> (<em>array_like</em>) – The sequence of approximate minimizers.</p></li>
<li><p><strong>r</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The reference, either a single array or a signal with the last
dimension indexing time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The sequence of cost evaluations or regret.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.soft_thresholding">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">soft_thresholding</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">penalty</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.soft_thresholding" title="Permalink to this definition">¶</a></dt>
<dd><p>Soft-thresholding.</p>
<p>The function computes the element-wise soft-trhesholding defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\operatorname{sign}(x) \max\{ |x| - \rho, 0 \}\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\rho\)</span> is a positive penalty parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – Where to evaluate the soft-thresholding.</p></li>
<li><p><strong>penalty</strong> (<em>float</em>) – The positive penalty parameter <span class="math notranslate nohighlight">\(\rho\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The soft-thresolding of <cite>x</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.solve">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.solve" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="tvopt.utils.square_norm">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">square_norm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.square_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the square norm of the given vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – The vector array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The square norm.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The function reshapes <cite>x</cite> to a column vector, so it does not correctly
handle n-dimensional arrays. For n-dim arrays use <cite>numpy.linalg.norm</cite>.</p>
</dd></dl>

<dl class="py function">
<dt id="tvopt.utils.uniform_quantizer">
<code class="sig-prename descclassname">tvopt.utils.</code><code class="sig-name descname">uniform_quantizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">step</span></em>, <em class="sig-param"><span class="n">thresholds</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#tvopt.utils.uniform_quantizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to perform uniform quantization.</p>
<p>The function applies the uniform quantization</p>
<div class="math notranslate nohighlight">
\[q(x) = \Delta \operatorname{floor}
\left( \frac{x}{\Delta} + \frac{1}{2} \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta\)</span> is the given step. Moreover, a saturation to
upper and lower thresholds is peformed if given as argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The array to be quantized.</p></li>
<li><p><strong>step</strong> (<em>float</em>) – The step of the quantizer.</p></li>
<li><p><strong>thresholds</strong> (<em>list</em><em>, </em><em>optional</em>) – The upper and lower saturation thresholds.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The quantized array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-tvopt">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-tvopt" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">tvopt</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Nicola Bastianello.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/tvopt.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>